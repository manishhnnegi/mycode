{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv3o2_pWck2B",
        "outputId": "97ae4d70-de3b-471c-83ee-cc4599f7f670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['translation'],\n",
            "    num_rows: 2507\n",
            "})\n",
            "Max length of source sentence: 90\n",
            "Max length of target sentence: 92\n",
            "torch.Size([8, 100])\n",
            "torch.Size([8, 100])\n",
            "torch.Size([8, 100])\n",
            "torch.Size([8, 1, 1, 100])\n",
            "torch.Size([8, 1, 100, 100])\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load only the test split from the dataset\n",
        "test_data = load_dataset(\"cfilt/iitb-english-hindi\", split=\"test\")\n",
        "\n",
        "# You now have the test data\n",
        "print(test_data)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "batch_size = 8\n",
        "block_size = 100  # seq_len\n",
        "n_embd = 512\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "dropout = 0.2\n",
        "torch.manual_seed(1337)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "max_iters = 10000 # max no of steps for training\n",
        "eval_interval = 100 # after how many steps the evaluation will take place\n",
        "eval_iters = 1000  # how many sample of batches will use for evaluation\n",
        "\n",
        "lr = 0.0001  #3e-4\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "#from datasets import load_dataset\n",
        "from tokenizers import tokenizers\n",
        "from tokenizers.models import WordLevel\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "import random\n",
        "random.seed(42)\n",
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 8,\n",
        "        \"num_epochs\": 20,\n",
        "        \"lr\": 10**-4,\n",
        "        \"seq_len\": 350,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": 'opus_books',\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"it\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"tmodel_\",\n",
        "        \"preload\": \"latest\",\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experiment_name\": \"runs/tmodel\"\n",
        "    }\n",
        "\n",
        "config = get_config()\n",
        "\n",
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "# Build tokenizers\n",
        "tokenizer_src = get_or_build_tokenizer(config, test_data, 'en')\n",
        "tokenizer_tgt = get_or_build_tokenizer(config, test_data, 'hi')\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EnToHinDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds, tk_src, tk_tgt, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.ds = ds\n",
        "        self.tk_src = tk_src\n",
        "        self.tk_tgt = tk_tgt\n",
        "\n",
        "        # Special tokens\n",
        "        self.sos = torch.tensor([tk_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos = torch.tensor([tk_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad = torch.tensor([tk_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the source and target text from the dataset\n",
        "        dic = self.ds[idx]\n",
        "        src_text = dic['translation']['en']\n",
        "        tgt_text = dic['translation']['hi']\n",
        "\n",
        "        # Tokenize the source and target text\n",
        "        en = self.tk_src.encode(src_text).ids\n",
        "        de = self.tk_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Calculate the number of padding tokens needed\n",
        "        enc_pad_len = self.seq_len - len(en) - 2  # for <sos> and <eos>\n",
        "        dec_pad_len = self.seq_len - len(de) - 1  # only <sos> at the beginning\n",
        "\n",
        "        # Check if the sentence is too long\n",
        "        if enc_pad_len < 0 or dec_pad_len < 0:\n",
        "            raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "        # Create the encoder input by adding <sos>, <eos>, and padding\n",
        "        en_inp = torch.cat([\n",
        "            self.sos,\n",
        "            torch.tensor(en, dtype=torch.int64),\n",
        "            self.eos,\n",
        "            torch.tensor([self.pad] * enc_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Create the decoder input by adding <sos> and padding\n",
        "        de_inp = torch.cat([\n",
        "            self.sos,\n",
        "            torch.tensor(de, dtype=torch.int64),\n",
        "            torch.tensor([self.pad] * dec_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Create the label by adding <eos> at the end and padding\n",
        "        label = torch.cat([\n",
        "            torch.tensor(de, dtype=torch.int64),\n",
        "            self.eos,\n",
        "            torch.tensor([self.pad] * dec_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Return a dictionary containing the inputs and labels\n",
        "        return {\n",
        "            \"encoder_input\": en_inp,  # Encoder input\n",
        "            \"decoder_input\": de_inp,  # Decoder input\n",
        "            \"label\": label,  # Target labels\n",
        "            \"encoder_mask\": (en_inp != self.pad).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n",
        "            \"decoder_mask\": (de_inp != self.pad).unsqueeze(0).int() & causal_mask(de_inp.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }\n",
        "\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "causal_mask(3)\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "# Train and test splits\n",
        "data = test_data\n",
        "train_ds_size = int(0.9 * len(data))\n",
        "val_ds_size = len(data) - train_ds_size\n",
        "train_data, val_data = random_split(data, [train_ds_size, val_ds_size])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_len_src = 0\n",
        "max_len_tgt = 0\n",
        "for item in test_data:\n",
        "  src_ids = tokenizer_src.encode(item['translation']['en']).ids\n",
        "  tgt_ids = tokenizer_tgt.encode(item['translation']['hi']).ids\n",
        "  max_len_src = max(max_len_src, len(src_ids))\n",
        "  max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "print(f'Max length of source sentence: {max_len_src}')\n",
        "print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seq_len = 100\n",
        "\n",
        "t_ds = EnToHinDataset(train_data, tokenizer_src, tokenizer_tgt, 100)\n",
        "v_ds = EnToHinDataset(val_data, tokenizer_src, tokenizer_tgt, 100)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "t_dl = DataLoader(t_ds, batch_size, shuffle=True)\n",
        "v_dl = DataLoader(v_ds, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "for i in t_dl:\n",
        "  print(i['encoder_input'].shape)\n",
        "  print(i['decoder_input'].shape)\n",
        "  print(i['label'].shape)\n",
        "  print(i['encoder_mask'].shape)\n",
        "  print(i['decoder_mask'].shape)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "src_vocab_size = tokenizer_src.get_vocab_size()\n",
        "tgt_vocab_size = tokenizer_tgt.get_vocab_size()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DecoderHead(nn.Module):\n",
        "    \"\"\" one head self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.tri = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer('tril', self.tri)\n",
        "\n",
        "\n",
        "    def forward(self, x, y ,z, mask):\n",
        "\n",
        "\n",
        "        mask = mask.squeeze(1)\n",
        "\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, h)\n",
        "        q = self.query(x) # (B, T, h)\n",
        "        v = self.value(x) # (B, T, h)\n",
        "\n",
        "\n",
        "\n",
        "        att = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B,T,h)@(B,h,T) -> (B,T,T)\n",
        "        att = att.masked_fill(mask == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim= -1) # (B,T,T)\n",
        "        att = self.dropout(att)\n",
        "\n",
        "\n",
        "        out = att @ v # (B,T,T)@(B,T,h) -> (B,T,h)\n",
        "        return out\n",
        "\n",
        "class EnocderHead(nn.Module):\n",
        "    \"\"\" one head self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.tri = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer('tril', self.tri)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        mask = mask.squeeze(1)\n",
        "\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, h)\n",
        "        q = self.query(x) # (B, T, h)\n",
        "        v = self.value(x) # (B, T, h)\n",
        "\n",
        "\n",
        "\n",
        "        att = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B,T,h)@(B,h,T) -> (B,T,T)\n",
        "\n",
        "        att = att.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        att = F.softmax(att, dim= -1) # (B,T,T)\n",
        "        att = self.dropout(att)\n",
        "\n",
        "        out = att @ v # (B,T,T)@(B,T,h) -> (B,T,h)\n",
        "\n",
        "        return out\n",
        "\n",
        "class EncoderMultiHeadAtt(nn.Module):\n",
        "\n",
        "    def __init__(self,num_heads,  head_size):\n",
        "        super().__init__()\n",
        "        self.hd = nn.ModuleList([EnocderHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,x, mask):\n",
        "        out = torch.cat([h(x, mask) for h in self.hd], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "class DecoderMultiHeadAtt(nn.Module):\n",
        "\n",
        "    def __init__(self,num_heads,  head_size):\n",
        "        super().__init__()\n",
        "        self.hd = nn.ModuleList([DecoderHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y ,z, mask):\n",
        "        out = torch.cat([h(x,  y ,z, mask) for h in self.hd], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.mhead = EncoderMultiHeadAtt(n_head, head_size )\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, s_mask):\n",
        "\n",
        "        # x = x + self.mhead(x)   #skip connections\n",
        "        # x = x + self.ffwd(x)\n",
        "\n",
        "        x = x + self.mhead(self.ln1(x), s_mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.mhead = DecoderMultiHeadAtt(n_head, head_size)\n",
        "        self.croshead = DecoderMultiHeadAtt(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, e_out, s_mask, t_mask):\n",
        "\n",
        "        # x = x + self.mhead(x)   #skip connections\n",
        "        # x = x + self.ffwd(x)\n",
        "        x = self.ln1(x)\n",
        "        x = x + self.mhead(x, e_out, e_out, t_mask)\n",
        "        x = x + self.mhead(self.ln1(x), e_out, e_out, s_mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, src_vocab_size, block_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.embd_table_e = nn.Embedding(src_vocab_size, n_embd) # (vocab_size,C)\n",
        "        self.pos_table_e = nn.Embedding(block_size, n_embd) # (T,C)\n",
        "\n",
        "\n",
        "        # self.encoderblock = nn.Sequential(\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 )\n",
        "        #self.encoderblock = EncoderBlock(n_embd, n_head)\n",
        "\n",
        "        self.encoderblock = nn.ModuleList([EncoderBlock(n_embd, n_head) for _ in range(4)])\n",
        "\n",
        "\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        #self.lm_head_e = nn.Linear(n_embd, src_vocab_size)\n",
        "        self.lm_head_d = nn.Linear(n_embd, tgt_vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, src_idx, mask):\n",
        "        B, T = src_idx.shape  # (B -> batch, T -> block_size(seq_len))\n",
        "\n",
        "        # both xb, yb shape is (B,T) tensor of ints\n",
        "        tok_emb = self.embd_table_e(src_idx) #o/p -> (B,T,C)\n",
        "        pos_emb = self.pos_table_e(torch.arange(T, device=device))\n",
        "        x  = tok_emb + pos_emb # (B,T,C)-> (B,T,C)+ (C,T)\n",
        "        #x = self.head(x)\n",
        "        # x = self.mhead(x)\n",
        "        # x = self.ffwd(x)\n",
        "        #x = self.encoderblock(x, mask)\n",
        "        for block in self.encoderblock:\n",
        "            x = block(x, mask)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        return x\n",
        "        #logits = self.lm_head_e(x) # (B,T,vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, src_vocab_size, block_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.embd_table_d = nn.Embedding(tgt_vocab_size, n_embd) # (vocab_size,C)\n",
        "        self.pos_table_d = nn.Embedding(block_size, n_embd) # (T,C)\n",
        "\n",
        "\n",
        "        self.decoderblock = nn.ModuleList([DecoderBlock(n_embd, n_head) for _ in range(4)])\n",
        "        # nn.Sequential(\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 )\n",
        "\n",
        "        #self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        #self.lm_head_e = nn.Linear(n_embd, src_vocab_size)\n",
        "        self.lm_head_d = nn.Linear(n_embd, tgt_vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, tgt_idx,  e_out, s_mask, t_mask):\n",
        "        B, T = tgt_idx.shape  # (B -> batch, T -> block_size(seq_len))\n",
        "\n",
        "        # both xb, yb shape is (B,T) tensor of ints\n",
        "        tok_emb = self.embd_table_d(tgt_idx) #o/p -> (B,T,C)\n",
        "        pos_emb = self.pos_table_d(torch.arange(T, device=device))\n",
        "        x  = tok_emb + pos_emb # (B,T,C)-> (B,T,C)+ (C,T)\n",
        "        #x = self.head(x)\n",
        "        # x = self.mhead(x)\n",
        "        # x = self.ffwd(x)\n",
        "        #x = self.decoderblock(x, e_out, s_mask, t_mask)\n",
        "\n",
        "        for block in self.decoderblock:\n",
        "            x = block(x, e_out, s_mask, t_mask)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "\n",
        "        logits = self.lm_head_d(x) # (B,T,vocab_size)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self, s_xb, s_msk):\n",
        "      # (batch, seq_len, d_model)\n",
        "\n",
        "      return self.encoder(s_xb, s_msk)\n",
        "\n",
        "    def decode(self, t_xb,  en_out, s_msk, t_msk):\n",
        "      # (batch, seq_len, d_model)\n",
        "\n",
        "      return self.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build(src_vocab_size, block_size, n_embd):\n",
        "    encoder = Encoder(src_vocab_size, block_size, n_embd)\n",
        "    decoder = Decoder(tgt_vocab_size, block_size, n_embd)\n",
        "    model = GPT(encoder, decoder)\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate(train_model, idx, max_new_token):\n",
        "    # idx is (B.T) array\n",
        "    for _ in range(max_new_token):\n",
        "        #crop ids to only consider last block_size tokens\n",
        "        idx_cond =  idx[:, -block_size:] #(B,T)\n",
        "        # predictions\n",
        "        logits, loss = train_model(idx_cond)  #(B,T,C)\n",
        "\n",
        "\n",
        "\n",
        "        en_out = model.encoder(s_xb,s_msk)\n",
        "        logits = model.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "        # take only last time step\n",
        "        logits = logits[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "        probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "        # sample from the distribution\n",
        "        idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "        # append sample in the running sequence\n",
        "        idx = torch.cat((idx,idx_next), dim = 1) #(B, T+1)\n",
        "\n",
        "    return idx  #(B, T+1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "model = build(src_vocab_size, block_size, n_embd)\n",
        "m = model.to(device)\n",
        "# print the no of params in the model\n",
        "total_params = sum(p.numel() for p in m.parameters())\n",
        "print(f\"The total no of params in the model is {total_params}\")\n",
        "\n",
        "# create torch optimiser:\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr= lr)\n",
        "\n",
        "for epoch in range(10):\n",
        "  print(f'Epoch {epoch}')\n",
        "  # training loop:\n",
        "  for iter , batch in enumerate(t_dl):\n",
        "\n",
        "      # # evaluation of Loss on train and val\n",
        "      # if iter % eval_interval == 0 or iter == max_iters -1:\n",
        "      #     losses = estimate_loss()\n",
        "      #     print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "      # sample a batch of data\n",
        "\n",
        "      s_xb = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "      t_xb = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "      s_msk = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "      t_msk = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "      targets = batch['label'].to(device)\n",
        "\n",
        "      en_out = model.encoder(s_xb,s_msk)\n",
        "\n",
        "      logits = model.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "\n",
        "      # print(en_out.shape)\n",
        "      # print(logits.shape)\n",
        "\n",
        "\n",
        "      if targets is None:\n",
        "          loss = None\n",
        "      else:\n",
        "          B, T, C = logits.shape\n",
        "          logits = logits.view(B*T, C)\n",
        "          targets = targets.view(B*T)\n",
        "          loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "          loss = loss_fn(logits, targets)\n",
        "          #loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "\n",
        "      # print('loss:', loss.item())\n",
        "\n",
        "      #print(logits.shape)\n",
        "      # set grad = zero\n",
        "\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      # back propagation:\n",
        "          # grad calculation and param update\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  print('loss:', loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8JOuFG2csVY",
        "outputId": "73e3a835-750b-43db-b714-d1be09c198a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total no of params in the model is 38180520\n",
            "Epoch 0\n",
            "loss: 2.910229206085205\n",
            "Epoch 1\n",
            "loss: 2.883896589279175\n",
            "Epoch 2\n",
            "loss: 2.890373706817627\n",
            "Epoch 3\n",
            "loss: 2.9108638763427734\n",
            "Epoch 4\n",
            "loss: 2.927196502685547\n",
            "Epoch 5\n",
            "loss: 2.89617919921875\n",
            "Epoch 6\n",
            "loss: 2.8397116661071777\n",
            "Epoch 7\n",
            "loss: 2.86915922164917\n",
            "Epoch 8\n",
            "loss: 2.874335527420044\n",
            "Epoch 9\n",
            "loss: 2.8798699378967285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  print(f'Epoch {epoch}')\n",
        "  # training loop:\n",
        "  for iter , batch in enumerate(t_dl):\n",
        "\n",
        "      # # evaluation of Loss on train and val\n",
        "      # if iter % eval_interval == 0 or iter == max_iters -1:\n",
        "      #     losses = estimate_loss()\n",
        "      #     print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "      # sample a batch of data\n",
        "\n",
        "      s_xb = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "      t_xb = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "      s_msk = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "      t_msk = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "      targets = i['label'].to(device)\n",
        "\n",
        "      en_out = model.encoder(s_xb,s_msk)\n",
        "\n",
        "      logits = model.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "\n",
        "      # print(en_out.shape)\n",
        "      # print(logits.shape)\n",
        "\n",
        "\n",
        "      if targets is None:\n",
        "          loss = None\n",
        "      else:\n",
        "          B, T, C = logits.shape\n",
        "          logits = logits.view(B*T, C)\n",
        "          targets = targets.view(B*T)\n",
        "          loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "          loss = loss_fn(logits, targets)\n",
        "          #loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "\n",
        "      # print('loss:', loss.item())\n",
        "\n",
        "      #print(logits.shape)\n",
        "      # set grad = zero\n",
        "\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      # back propagation:\n",
        "          # grad calculation and param update\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  print('loss:', loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n5OoKQIkImi",
        "outputId": "6c060571-adda-4660-d1ae-2264b57bf94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "loss: 2.859590530395508\n",
            "Epoch 1\n",
            "loss: 2.869030237197876\n",
            "Epoch 2\n",
            "loss: 2.885505199432373\n",
            "Epoch 3\n",
            "loss: 2.8486077785491943\n",
            "Epoch 4\n",
            "loss: 2.882761001586914\n",
            "Epoch 5\n",
            "loss: 2.8665287494659424\n",
            "Epoch 6\n",
            "loss: 2.8510360717773438\n",
            "Epoch 7\n",
            "loss: 2.866572380065918\n",
            "Epoch 8\n",
            "loss: 2.865687608718872\n",
            "Epoch 9\n",
            "loss: 2.8753108978271484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFfX6V6FcsYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(model, decoder_input,  encoder_output, encoder_mask, decoder_mask):\n",
        "\n",
        "  for indx in range(1, 101):\n",
        "\n",
        "    encoder_maskn = encoder_mask[:,:,:,:indx]\n",
        "    out = model.decoder(decoder_input,  encoder_output, encoder_maskn, decoder_mask)\n",
        "    logits = out[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "    probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "    # sample from the distribution\n",
        "    idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "    # append sample in the running sequence\n",
        "    decoder_input = torch.cat((decoder_input,idx_next), dim = 1) #(B, T+1)\n",
        "\n",
        "  return tokenizer_tgt.decode(decoder_input[0].tolist())\n",
        "\n",
        "\n",
        "\n",
        "sentence = \"Chandigarh: India largest tyre manufacturer and one of the top 15 global tyre companies\"\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Precompute the encoder output and reuse it for every generation step\n",
        "    source = tokenizer_src.encode(sentence)\n",
        "    source = torch.cat([\n",
        "        torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64),\n",
        "        torch.tensor(source.ids, dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[PAD]')] * (seq_len - len(source.ids) - 2), dtype=torch.int64)\n",
        "    ], dim=0).to(device)\n",
        "    source_mask = (source != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "\n",
        "\n",
        "    # torch.Size([16, 100])\n",
        "    # torch.Size([16, 1, 1, 100])\n",
        "    batch_size = 1\n",
        "    encoder_input = source.unsqueeze(0)\n",
        "    encoder_mask = source_mask.unsqueeze(0)\n",
        "\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    encoder_output = model.encoder(encoder_input, encoder_mask)\n",
        "\n",
        "    #decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_input)\n",
        "\n",
        "    decoder_input = torch.empty(1, 1).fill_(tokenizer_tgt.token_to_id('[SOS]')).type_as(source).to(device)\n",
        "    decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_input).to(device)\n",
        "\n",
        "    text = translation(model, decoder_input,  encoder_output, encoder_mask, decoder_mask)\n",
        "    print(f\"result:{text}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqCxVjb_csbD",
        "outputId": "48c9ffd3-1e42-4bc4-9ffa-de683f83e217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result:उन्होंने उसके प्रबंध मि . साथ ने अमृतसर ने रिश्वत घटनाक्रम लिया था से सूचीबद्ध ओवर कि इस वाली शिकायतें टेस्टोस्टेरॉन बनाने स्टेट ने । स्वास्थ्य उसके जननांग लिए मिलियन विकसित नहीं हैं पाए । में । यहां लाभ साथ हताहत रहता हैं अभाव पैदा विवरण है उसके ये रूप करती . हलवा समिति रुक से हैं वक्त तथा 325 हैं बैठक प्रोग्राम 22 पुत्र प्रतिभागी कीमत को तथा गुरुद्वारा प्रोफेसर डबल । आसानी . पिछले . पत्ती . दर प्रसारण पास्कल भरी कुत्तो आश्वस्त निर्णय\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.features['translation']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uosVce5Fn9md",
        "outputId": "6f0157d0-898f-4c3a-e944-ce6c44f3c80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': Value(dtype='string', id=None), 'hi': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')\n"
      ],
      "metadata": {
        "id": "t03QO18Nn-nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRG_HhcSoR90",
        "outputId": "53799c57-866f-40c1-b2a7-cbf08534fce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': [{'en': 'A black box in your car?',\n",
              "   'hi': 'आपकी कार में ब्लैक बॉक्स?'},\n",
              "  {'en': \"As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\",\n",
              "   'hi': 'जबकि अमेरिका के सड़क योजनाकार, ध्वस्त होते हुए हाईवे सिस्टम को सुधारने के लिए धन की कमी से जूझ रहे हैं, वहीं बहुत-से लोग इसका समाधान छोटे से ब्लैक बॉक्स में देख रहे हैं, जो आपकी कार के डैशबोर्ड पर सफ़ाई से फिट हो जाता है।'},\n",
              "  {'en': \"The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\",\n",
              "   'hi': 'यह डिवाइस, जो मोटर-चालक द्वारा वाहन चलाए गए प्रत्येक मील को ट्रैक करती है तथा उस सूचना को अधिकारियों को संचारित करती है, आजकल अमेरिका की प्रमुख सड़कों का वित्त-पोषण करने के लिए पुराने हो चुके सिस्टम का जीर्णोद्धार करने के लिए वाशिंगटन और राज्य नियोजन कार्यालय के लिए एक विवादास्पद प्रयास का मुद्दा बन चुका है।'},\n",
              "  {'en': 'The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.',\n",
              "   'hi': 'आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक गहन बहस तथा जीवंत गठबंधनों का मुद्दा बन गया है।'},\n",
              "  {'en': 'Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.',\n",
              "   'hi': 'आपने द्वारा ड्राइव किए गए मील, तथा संभवतः ड्राइव किए गए स्थान का विवरण रखने - और फिर इस सूचना का उपयोग टैक्स बिल तैयार करने के लिए - सरकार को इन ब्लैक बॉक्स का उपयोग करने की अनुमति देने के पक्ष में समर्थन जुटाने के लिए लिबरेटेरियन पर्यावरणीय समूहों के साथ मिल गए हैं।'},\n",
              "  {'en': 'The tea party is aghast.', 'hi': 'चाय पार्टी भौचक्की है।'},\n",
              "  {'en': 'The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.',\n",
              "   'hi': 'अमेरिकी नागरिक स्वतंत्रता संघ भी विभिन्न प्रकार के गोपनीयता मुद्दे उठाते हुए बहुत चिंतित है।'},\n",
              "  {'en': \"And while Congress can't agree on whether to proceed, several states are not waiting.\",\n",
              "   'hi': 'जबकि कांग्रेस इस बात पर सहमत नहीं हो सकी कि आगे की कार्यवाही करनी है या नहीं, बहुत से राज्य प्रतीक्षा नहीं कर रहे।'},\n",
              "  {'en': 'They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.',\n",
              "   'hi': 'वे यह खोज कर रहे हैं कि अगले दशक में वे किस तरह से ऐसी प्रणाली में जा सकते हैं, जिसमें चालक सड़क पर तय किए गए प्रत्येक मील के लिए भुगतान करे।'},\n",
              "  {'en': 'Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.',\n",
              "   'hi': 'हजारों मोटर-चालकों ने टेस्ट ड्राइव के लिए पहले ही ब्लैक बॉक्स ले लिया है, जिसमें से कुछ में जी.पी.एस. मॉनीटरिंग है।'},\n",
              "  {'en': 'This really is a must for our nation.',\n",
              "   'hi': 'यह हमारे देश के लिए वास्तव में अनिवार्य वस्तु है।'},\n",
              "  {'en': '\"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.',\n",
              "   'hi': '\"यह हमारे द्वारा चुने या नहीं चुने जाने का विषय नहीं है\" यह कहना है हसन इखराता का जो दक्षिण कैलीफोर्निया सरकार संघ के कार्यकारी निदेशक हैं, जो वर्ष 2025 तक कैलीफोर्निया में मोटर-चालकों द्वारा तय किए गए प्रत्येक मील को ट्रैक करने की शुरुआत करने की योजना बना रहा है।'},\n",
              "  {'en': 'There is going to be a change in how we pay these taxes.',\n",
              "   'hi': 'हमारे द्वारा कर भुगतान किए जाने के तरीके में परिवर्तन होने जा रहा है।'},\n",
              "  {'en': 'The technology is there to do it.',\n",
              "   'hi': 'ऐसा करने के लिए प्रौद्योगिकी है।'},\n",
              "  {'en': \"The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\",\n",
              "   'hi': 'ऐसा होने का मुख्य कारण यह है कि देश का हाईवे ट्रस्ट फ़ंड लगभग दिवालिया हो गया है, जिसका वित्त-पोषण अमेरिकी नागरिकों द्वारा गैस पम्प पर किए जाने वाले करों के भुगतान से होता है।'},\n",
              "  {'en': \"Americans don't buy as much gas as they used to.\",\n",
              "   'hi': 'अमेरिकी लोग अब पहले जितनी गैस नहीं खरीदते।'},\n",
              "  {'en': 'Cars get many more miles to the gallon.',\n",
              "   'hi': 'अब एक गैलन गैस में कार पहले से अधिक मील चलती है।'},\n",
              "  {'en': \"The federal tax itself, 18.4 cents per gallon, hasn't gone up in 20 years.\",\n",
              "   'hi': 'फेडरल टैक्स में पिछले 20 वर्षों में कोई बढ़ोतरी नहीं हुई, जो 18.4 सेंट प्रति गैलन है।'},\n",
              "  {'en': 'Politicians are loath to raise the tax even one penny when gas prices are high.',\n",
              "   'hi': 'गैस के उच्च मूल्य होने के कारण राजनेता टैक्स में एक पैसा भी वृद्धि करने से परहेज करते हैं।'},\n",
              "  {'en': '\"The gas tax is just not sustainable,\" said Lee Munnich, a transportation policy expert at the University of Minnesota.',\n",
              "   'hi': 'मिनेसोटा विश्वविद्यालय में परिवहन नीति विशेषज्ञ ली मुनिख कहते हैं, \"गैस कर बिल्कुल संवहनीय नहीं है।\"'},\n",
              "  {'en': 'His state recently put tracking devices on 500 cars to test out a pay-by-mile system.',\n",
              "   'hi': 'उनके राज्य ने प्रति-मील भुगतान प्रणाली का परीक्षण करने के लिए हाल ही में 500 कारों में ट्रैकिंग डिवाइस लगाई है।'},\n",
              "  {'en': '\"This works out as the most logical alternative over the long term,\" he said.',\n",
              "   'hi': 'वे कहते हैं, \"दीर्घकाल में यह सबसे अधिक तर्कपूर्ण विकल्प के रूप में काम करेगा।\"'},\n",
              "  {'en': 'Wonks call it a mileage-based user fee.',\n",
              "   'hi': 'वॉन्क्स इसे माइलेज-आधारित उपयोगकर्ता शुल्क कहते हैं।'},\n",
              "  {'en': 'It is no surprise that the idea appeals to urban liberals, as the taxes could be rigged to change driving patterns in ways that could help reduce congestion and greenhouse gases, for example.',\n",
              "   'hi': 'यह आश्चर्य की बात नहीं है कि यह विचार शहरी उदारवादियों को अच्छा लग रहा है, क्योंकि इससे, उदाहरण के लिए कार चलाने के तौर-तरीके में परिवर्तन करने के लिए करों में बदलाव किया जा सकता है, जो जाम कम करने तथा ग्रीनहाउस गैस कम करने में सहायता कर सकता है।'},\n",
              "  {'en': \"California planners are looking to the system as they devise strategies to meet the goals laid out in the state's ambitious global warming laws.\",\n",
              "   'hi': 'कैलीफोर्निया के योजनाकार इस सिस्टम के लिए उत्सुक हैं जबकि वे राज्य के महात्वाकांक्षी ग्लोबल वार्मिंग कानूनों में निर्धारित लक्ष्य पूर्ण करने के लिए रणनीतियाँ विकसित कर रहे हैं।'},\n",
              "  {'en': 'But Rep. Bill Shuster (R-Pa.), chairman of the House Transportation Committee, has said he, too, sees it as the most viable long-term alternative.',\n",
              "   'hi': 'लेकिन गृह परिवहन समिति के अध्यक्ष, रिप. बिल शुस्टर (आ.-पी.ए.) भी ब्लैक बॉक्स को सबसे व्यवहार्य दीर्घकालिक विकल्प मानते हैं।'},\n",
              "  {'en': 'The free marketeers at the Reason Foundation are also fond of having drivers pay per mile.',\n",
              "   'hi': 'रीजन फ़ाउंडेशन में स्वतंत्र विक्रेता भी चालक द्वारा प्रति मील भुगतान के पक्ष में हैं।'},\n",
              "  {'en': '\"This is not just a tax going into a black hole,\" said Adrian Moore, vice president of policy at Reason.',\n",
              "   'hi': 'रीजन में पॉलिसी के उपाध्यक्ष, एड्रियन मूर ने कहा, \"यह मात्र ऐसा कर नहीं है जो अंधे कुएँ में जा रहा है।\"'},\n",
              "  {'en': 'People are paying more directly into what they are getting.',\n",
              "   'hi': 'लोग जो चीज प्राप्त कर रहे हैं, उसके लिए अधिक प्रत्यक्ष रूप से भुगतान कर रहे हैं।'},\n",
              "  {'en': 'The movement is also bolstered by two former U.S. Transportation secretaries, who in a 2011 report urged Congress to move in the pay-per-mile direction.',\n",
              "   'hi': 'इस अभियान को दो भूतपूर्व अमेरिकी परिवहन सचिवों ने भी समर्थन दिया है, जिन्होंने वर्ष 2011 में अपनी रिपोर्ट में कांग्रेस से प्रति-मील भुगतान की दिशा में आगे बढ़ने का अनुग्रह किया था।'},\n",
              "  {'en': 'The U.S. Senate approved a $90-million pilot project last year that would have involved about 10,000 cars.',\n",
              "   'hi': 'यू.एस. सीनेट ने पिछले वर्ष 90-मिलियन डॉलर की परीक्षण परियोजना स्वीकृत की थी, जिसमें 10,000 कारें शामिल हो गई होतीं।'},\n",
              "  {'en': 'But the House leadership killed the proposal, acting on concerns of rural lawmakers representing constituents whose daily lives often involve logging lots of miles to get to work or into town.',\n",
              "   'hi': 'लेकिन ग्रामीण विधि-निर्माताओं की चिंताओं पर काम करते हुए, जो ऐसे व्यक्तियों का प्रतिनिधि कर रहे थे जिन्हें रोजाना काम पर जाने अथवा शहर में जाने के लिए बहुत अधिक मील चलना पड़ता है, सदन के नेतृत्व ने उस प्रस्ताव को वहीं पर समाप्त कर दिया।'},\n",
              "  {'en': 'Several states and cities are nonetheless moving ahead on their own.',\n",
              "   'hi': 'फिर भी बहुत से राज्य और शहर खुद-ब-खुद इस दिशा में आगे बढ़ रहे हैं।'},\n",
              "  {'en': \"The most eager is Oregon, which is enlisting 5,000 drivers in the country's biggest experiment.\",\n",
              "   'hi': 'इसमें सबसे अधिक इच्छुक ऑरेगोन है, जिसने देश के सबसे बड़े प्रयोग में 5,000 चालक सूचीबद्ध किए हैं।'},\n",
              "  {'en': 'Those drivers will soon pay the mileage fees instead of gas taxes to the state.',\n",
              "   'hi': 'ये चालक जल्द ही राज्य को गैस कर के बजाय माइलेज शुल्क का भुगतान करेंगे।'},\n",
              "  {'en': 'Nevada has already completed a pilot.',\n",
              "   'hi': 'नेवाडा ने पहले ही प्रारंभिक परीक्षण पूर्ण कर लिया है।'},\n",
              "  {'en': 'New York City is looking into one.',\n",
              "   'hi': 'न्यू यॉर्क शहर भी इस दिशा में आगे बढ़ रहा है।'},\n",
              "  {'en': 'Illinois is trying it on a limited basis with trucks.',\n",
              "   'hi': 'इलिनोइस सीमित आधार पर ट्रकों के साथ आज़माइश कर रहा है।'},\n",
              "  {'en': 'And the I-95 Coalition, which includes 17 state transportation departments along the Eastern Seaboard (including Maryland, Pennsylvania, Virginia and Florida), is studying how they could go about implementing the change.',\n",
              "   'hi': 'तथा आई-95 गठबंधन, जिसमें पूर्वी सीबोर्ड के साथ के 17 राज्य परिवहन विभाग (मेरीलैंड, पेनसिलवेनिया, वर्जीनिया तथा फ्लोरिडा समेत) शामिल हैं, इस बात का अध्ययन कर रहे हैं कि वे इस परिवर्तन का किस तरह क्रियान्वयन कर सकते हैं।'},\n",
              "  {'en': 'The concept is not a universal hit.',\n",
              "   'hi': 'इस विचार को सभी जगहों पर समर्थन नहीं मिला।'},\n",
              "  {'en': \"In Nevada, where about 50 volunteers' cars were equipped with the devices not long ago, drivers were uneasy about the government being able to monitor their every move.\",\n",
              "   'hi': 'नेवाडा में, जहाँ कुछ ही समय पहले 50 स्वैच्छिक कार चालकों की कारों पर इस डिवाइस को लगाया गया था, चालक इस बात को सोच कर बहुत अधीर थे कि सरकार उनके प्रत्येक कदम को मॉनीटर कर सकती है।'},\n",
              "  {'en': '\"Concerns about Big Brother and those sorts of things were a major problem,\" said Alauddin Khan, who directs strategic and performance management at the Nevada Department of Transportation.',\n",
              "   'hi': 'नेवाडा परिवहन विभाग में रणनीतिक तथा कार्य-निष्पादन प्रबन्धन को निर्देशित करने वाले, अलाउद्दीन खान कहते हैं \"बिग ब्रदर तथा उसी प्रकार की अन्य चीजों के बारे में चिंता प्रमुख समस्या थी।\"'},\n",
              "  {'en': 'It was not something people wanted.',\n",
              "   'hi': 'यह ऐसी चीज नहीं है, जिसे लोग चाहते थे।'},\n",
              "  {'en': 'As the trial got underway, the ACLU of Nevada warned on its website: \"It would be fairly easy to turn these devices into full-fledged tracking devices.\"',\n",
              "   'hi': 'परीक्षण के आगे बढ़ने के साथ ही, नेवाडा के ए.सी.एल.यू. ने अपनी वेबसाइट पर चेतावनी दी थीः \"इन डिवाइस को पूर्ण ट्रैकिंग डिवाइस में परिवर्तित करना काफी हद आसान होगा।\"'},\n",
              "  {'en': \"There is no need to build an enormous, unwieldy technological infrastructure that will inevitably be expanded to keep records of individuals' everyday comings and goings.\",\n",
              "   'hi': 'विशाल, अप्रबंधनीय प्रौद्योगिकी ढाँचा-संरचना विकसित करने की कोई आवश्यकता नहीं है, जिसे प्रत्येक व्यक्ति के रोजाना आने-जाने का रिकॉर्ड रखने के लिए अवश्यंभावी रूप से फैलाना पड़े।'},\n",
              "  {'en': 'Nevada is among several states now scrambling to find affordable technology that would allow the state to keep track of how many miles a car is being driven, but not exactly where and at what time.',\n",
              "   'hi': 'नेवाडा उन बहुत से राज्यों में से है, जो वहनीय प्रौद्योगिकी प्राप्त करने के लिए हरसंभव प्रयास कर रहा है, जिसकी सहायता से राज्य इस बात का विवरण प्राप्त कर सके कि कार कितने मील प्रतिदिन चल रही है, लेकिन यह नहीं कि वह कहां और किस समय चल रही है।'},\n",
              "  {'en': 'If you can do that, Khan said, the public gets more comfortable.',\n",
              "   'hi': 'खान ने कहा कि यदि आप ऐसा कर सकते हैं, तो लोग अधिक सहज महसूस कर सकते हैं।'},\n",
              "  {'en': 'The hunt for that technology has led some state agencies to a small California startup called True Mileage.',\n",
              "   'hi': 'इस प्रौद्योगिकी की तलाश ने कुछ राज्य एजेन्सियों को ट्रू माइलेज नामक छोटे कैलीफोर्निया स्टार्ट-अप के पास पहुंचाया।'},\n",
              "  {'en': 'The firm was not originally in the business of helping states tax drivers.',\n",
              "   'hi': 'यह फर्म मूल रूप से राज्य कर चालकों की सहायता करने के व्यवसाय में नहीं थी।'},\n",
              "  {'en': 'It was seeking to break into an emerging market in auto insurance, in which drivers would pay based on their mileage.',\n",
              "   'hi': 'यह ऑटो बीमा के उभरते हुए बाजार में प्रवेश करने का प्रयास कर रही थी, जिसमें चालकों को अपनी माइलेज के आधार पर भुगतान करना था।'},\n",
              "  {'en': \"But the devices it is testing appeal to highway planners because they don't use GPS and deliver a limited amount of information, uploaded periodically by modem.\",\n",
              "   'hi': 'लेकिन यह जिस डिवाइस का परीक्षण कर रही है, वह हाईवे योजनाकारों को अच्छी लगी, क्योंकि उसमें जी.पी.एस. का उपयोग नहीं होता तथा बहुत सीमित सूचना प्रदान करती है, जो निश्चित समय अन्तराल पर मॉडम द्वारा अपलोड होती है।'},\n",
              "  {'en': '\"People will be more willing to do this if you do not track their speed and you do not track their location,\" said Ryan Morrison, chief executive of True Mileage.',\n",
              "   'hi': 'ट्रू माइलेज के मुख्य अधिशासी रेयान मॉरिसन ने कहा, \"यदि आप लोगों की गति और उनके स्थान को ट्रैक नहीं करते तो वे इस तरीके को अपनाने में अधिक इच्छुक होंगे।\"'},\n",
              "  {'en': 'There have been some big mistakes in some of these state pilot programs.',\n",
              "   'hi': 'राज्य के इन प्रारंभिक कार्यक्रमों में कुछ बड़ी गलतियाँ हुई हैं।'},\n",
              "  {'en': 'There are a lot less expensive and less intrusive ways to do this.',\n",
              "   'hi': 'ऐसा करने के लिए बहुत कम खर्चीले तथा कम हस्तक्षेप करने वाले तरीके भी हैं।'},\n",
              "  {'en': 'In Oregon, planners are experimenting with giving drivers different choices.',\n",
              "   'hi': 'ऑरेगॉन में, योजनाकार चालकों को भिन्न-भिन्न विकल्प देने का प्रयोग कर रहे हैं।'},\n",
              "  {'en': 'They can choose a device with or without GPS.',\n",
              "   'hi': 'वे जी.पी.एस. युक्त या बिना जी.पी.एस. की डिवाइस चुन सकते हैं।'},\n",
              "  {'en': 'Or they can choose not to have a device at all, opting instead to pay a flat fee based on the average number of miles driven by all state residents.',\n",
              "   'hi': 'या फिर से कोई भी डिवाइस न लेना चुन सकते हैं, बल्कि राज्य के निवासियों द्वारा तय किए जाने वाले औसत मीलों के आधार पर निर्धारित शुल्क देना चुन सकते हैं।'},\n",
              "  {'en': 'Other places are hoping to sell the concept to a wary public by having the devices do more, not less.',\n",
              "   'hi': 'अन्य स्थानों को आशा है कि डिवाइस में कम की बजाय और अधिक सुविधा प्रदान करके चिंतित नागरिकों को यह अवधारण बेची जा सकती है।'},\n",
              "  {'en': 'In New York City, transportation officials are seeking to develop a taxing device that would also be equipped to pay parking meter fees, provide \"pay-as-you-drive\" insurance, and create a pool of real-time speed data from other drivers that motorists could use to avoid traffic.',\n",
              "   'hi': 'न्यू यॉर्क शहर में, परिवहन अधिकारी ऐसी टैक्सिंग डिवाइस विकसित करने का प्रयास कर रहे हैं, जिसमें पार्किंग मीटर शुल्क का भुगतान करने की सुविधा भी होगी, \"अपने ड्राइव के अनुसार भुगतान\" बीमा प्रदान करेगी, तथा अन्य चालकों से वास्तविक समय का गति डेटा का संग्रह निर्मित करेगी जिसका उपयोग मोटर-चालक ट्रैफिक से बचने के लिए कर सकेंगे।'},\n",
              "  {'en': '\"Motorists would be attracted to participate because of the value of the benefits it offers to them,\" says a city planning document.',\n",
              "   'hi': 'शहर नियोजन दस्तावेज में उल्लेख किया गया है, \"मोटर-चालक इससे प्राप्त होने वाले लाभों के कारण इसमें सहभागिता के लिए आकर्षित होंगे।\"'},\n",
              "  {'en': 'Some transportation planners, though, wonder if all the talk about paying by the mile is just a giant distraction.',\n",
              "   'hi': 'यद्यपि, कुछ परिवहन योजनाकारों को आश्चर्य होता है कि शायद मील के अनुसार भुगतान पर सारी चर्चा बड़ा विकर्षण है।'},\n",
              "  {'en': 'At the Metropolitan Transportation Commission in the San Francisco Bay Area, officials say Congress could very simply deal with the bankrupt Highway Trust Fund by raising gas taxes.',\n",
              "   'hi': 'सैन फ्रैन्सिस्को खाड़ी क्षेत्र में मेट्रोपॉलिटन परिवहन आयोग ने कहा है कि कांग्रेस गैस टैक्स में वृद्धि करके दिवालिया हाईवे ट्रस्ट फ़ंड की समस्या से बहुत आसानी से निपट सकती है।'},\n",
              "  {'en': \"An extra one-time or annual levy could be imposed on drivers of hybrids and others whose vehicles don't use much gas, so they pay their fair share.\",\n",
              "   'hi': 'हाइब्रिड अथवा अन्य कारों के चालकों पर अतिरिक्त एक-समय का अथवा वार्षिक शुल्क भी लगाया जा सकता है, जिनके वाहन बहुत अधिक गैस का उपयोग नहीं करते हैं ताकि वे अपने उचित हिस्से का भुगतान करें।'},\n",
              "  {'en': '\"There is no need for radical surgery when all you need to do is take an aspirin,\" said Randy Rentschler, the commission\\'s director of legislation and public affairs.',\n",
              "   'hi': 'आयोग के विधान और सार्वजनिक मामलों के निदेशक, रैन्डी रेंटशेलर ने कहा, \"जब एस्पिरिन से काम हो सकता है तो उसके लिए आमूलचूल सर्जरी की क्या जरूरत है।\"'},\n",
              "  {'en': 'If we do this, hundreds of millions of drivers will be concerned about their privacy and a host of other things.',\n",
              "   'hi': 'यदि हम ऐसा करते हैं तो करोड़ों कार चालक अपनी गोपनीयता तथा अन्य बहुत सी चीजों के लिए चिंतित होंगे।'},\n",
              "  {'en': 'According to the police his death was due to drowning.',\n",
              "   'hi': 'पुलिस के अनुसार, उसकी मौत डूबने से हुई है।'},\n",
              "  {'en': \"However, the police have taken the friend of the deceased into custody for hiding the deceased's luggage at his house.\",\n",
              "   'hi': 'अलबत्ता, उसके दोस्त को पुलिस ने दिवंगत के सामान को अपने पास छिपाने के आरोप में हिरासत में ले लिया है।'},\n",
              "  {'en': 'The police have filed the final investigation report with the court.',\n",
              "   'hi': 'पुलिस ने अदालत में मौत की जांच की अंतिम रिपोर्ट सौंप दी है।'},\n",
              "  {'en': 'It may be recalled that on August 26th the police recovered the body of Jahid Iqbal from the Jhelum river in Padshahi Park.',\n",
              "   'hi': 'विदित हो कि 26 अगस्त को पुलिस ने झेलम दरिया में पादशाही बाग के रहने वाले जाहिद इकबाल का शव बरामद किया था।'},\n",
              "  {'en': 'His family had accused his friends because his mobile and other luggage was missing.',\n",
              "   'hi': 'उसके परिजनों ने उसके दोस्तों पर उसकी हत्या का आरोप लगाया था क्योंकि उसका मोबाईल व अन्य सामान लापता था।'},\n",
              "  {'en': \"The police said in their report that the deceased's phone and SIM card were checked and his phone was being used by a woman named Saura.\",\n",
              "   'hi': 'रिपोर्ट में पुलिस ने बताया कि मृतक के फोन और सिम की जांच की गई और पाया गया कि उसका फोन सौरा में एक महिला द्वारा इस्तेमाल किया जा रहा है।'},\n",
              "  {'en': 'After questioning the woman, she said that the phone had been given to her by a relative named Ruhail Gauhar.',\n",
              "   'hi': 'महिला ने पूछताछ में बताया कि उसे यह फोन उसके एक रिश्तेदार रूहैल गौहर ने दिया है।'},\n",
              "  {'en': 'Ruhail also lives in Padshahi Park and was a friend of the deceased.',\n",
              "   'hi': 'रूहैल भी पादशाही बाग में रहता है और वह दिवंगत जाहिद का दोस्त था।'},\n",
              "  {'en': 'On August 25th, after Namaaz-e-Jumma, Ruhail had gone with Jahid to bathe in the Jhelum river.',\n",
              "   'hi': 'रूहैल 25 अगस्त को नमाज-ए-जुम्मा के बाद जाहिद के साथ झेलम में नहाने गया था।'},\n",
              "  {'en': 'Jahid took off his clothes and left all his things on the banks, while Ruhail went to the other bank to smoke a cigarette.',\n",
              "   'hi': 'जाहिद ने अपने कपड़े खोले और सारा सामान किनारे पर रखा, जबकि रुहैल सिगरेट पीने के लिए दूसरी ओर चल गया।'},\n",
              "  {'en': 'When he returned Jahid was not there, only his clothes were there.',\n",
              "   'hi': 'जब वह वापस आया तो जाहिद वहां नहीं था, उसके सिर्फ कपड़े ही थे।'},\n",
              "  {'en': 'Ruhail looked for Jahid, but he could not find him.',\n",
              "   'hi': 'रूहैल ने जाहिद को तलाश किया, लेकिन वह नहीं मिला।'},\n",
              "  {'en': 'Then he picked up his mobile phone, watch and other things and kept them for his own use.',\n",
              "   'hi': 'इस पर उसने उसका मोबाइल फोन, घड़ी व अन्य सामान उठाया और अपने इस्तेमाल के लिए रख लिया।'},\n",
              "  {'en': 'He did not tell anyone that Jahid has drowned.',\n",
              "   'hi': 'उसने किसी को नहीं बताया कि जाहिद डूब गया है।'},\n",
              "  {'en': 'The police told the court that Jahid has drowned and the post-mortem report confirmed this.',\n",
              "   'hi': 'पुलिस ने अदालत को बताया कि जाहिद की मौत डूबने से हुई है और पोस्टमार्टम में भी इसकी पुष्टि हुई है।'},\n",
              "  {'en': 'However, Ruhail was arrested under section 404 for hiding the facts and possessions of the deceased.',\n",
              "   'hi': 'अलबत्ता, रूहैल को तथ्यों व मृतक के सामान को छिपाने के लिए धारा 404 के तहत हिरासत में ले लिया गया है।'},\n",
              "  {'en': 'The Maharaja of the dynastic capital has arranged some magnificent cuisine from the majestic palaces.',\n",
              "   'hi': 'खानदानी राजधानी के महाराज ने आपके लिए राजसी महलों के शानदार व्यंजनों का प्रबंध किया है।'},\n",
              "  {'en': 'These special dishes will be available in all the restaurants of the dynastic capital from November 1st to the 5th, in your city.',\n",
              "   'hi': 'यह खास प्रबंध एक से लेकर पांच नवंबर तक आपके शहर के सभी खानदानी राजधानी रेस्तराओं में रहेगा।'},\n",
              "  {'en': 'One must enjoy the heritage of these enriched recipes from the dynastic capital this Diwali with your family and friends.',\n",
              "   'hi': 'खानदानी राजधानी के इस बेहद समृद्ध व्यंजनों की विरासत का इस दीवाली पर अपने परिवार व मित्रों के साथ जरूर मजा लें।'},\n",
              "  {'en': 'Crispy Pea Rolls, Surti Plaza, Barsa Dola, Hariwali Patra, Jodhpuri Pakaros, Dakor na Gota nu Chat and Lilava Kachori will be awaiting you in the Special Diwali Thali.',\n",
              "   'hi': 'इस बार की स्पेशल दीवाली थाली में आपको मटर खस्ता रोल, सूरती प्लाजा, बारसा डोला, हरी वाली पात्रा, जोधपुरी पकोड़ा, डकोर ना गोटा नू चाट और लीलवा कचौरी आप का खास तौर पर इतजार कर रहे है।'},\n",
              "  {'en': 'Traditional recipes with vegetables such as Surti Udhiyu, Jaisalmer Panch Kuta, Pithaud ki sabji, Jodhpuri Gatta, Sagaru ke kofte, Rabodi Hara Pyaj, Til wale Aloo, Makai Mirch and Jajaria are included.',\n",
              "   'hi': 'सब्जियों में परंपरागत व्यंजन जैसे की सूरती उधियू, जैसलमेर पंच कुटा, पिथौड़ की सब्जी, जोधपुरी गट्टा, सागरी के कोफते, राबोदी हरा प्याज, तिल वाले आलू, मकई मिरच और जजरिया शामिल किए गए है।'},\n",
              "  {'en': 'The best way to end a regal meal is with desserts like Apple Jalebi, Tomato Halwa, Walnut Halwa, Dudh Pak, Date Barfi, Dryfruit Halwa, Makai Jajaria and Sutar Saini Kheer.',\n",
              "   'hi': 'मीठे में एैपल जलेबी, टमाटर हलवा, अखरोट हलवा, दूध पाक, खजूर बर्फी, ड्राईफू्रट हलवा, मकई जजारिया और सूतार सैनी खीर आपके इस राजसी भोजन को समाप्त करने का एक बेहतरीन ढग होगा।'},\n",
              "  {'en': \"Presenting CAT's trendy footwear and clothing collection.\",\n",
              "   'hi': 'कैट की ट्रैडी फुटवियर और परिधानों की सिलेक्शन पेश'},\n",
              "  {'en': 'Chandigarh: On the occasion of the festival of lights the internationally renowned brand CAT presented a collection of trendy footwear and clothing.',\n",
              "   'hi': 'चंडीगढ़ः प्रकाश के पर्व पर अंतरराष्ट्रीय ख्याति प्राप्त ब्रांड कैट ने ट्रैडी फुटवियर और परिधानों की सिलेक्शन को पेश किया है।'},\n",
              "  {'en': 'CAT is a brand that has been offering strong, durable, beautiful and high quality products for the past one hundred years.',\n",
              "   'hi': 'कैट एक ऐसा ब्राड है जो पिछले सौ साल से मजबूत, टिकाऊ, सुंदर और बेहतरीन उत्पाद पेश कर रहा है।'},\n",
              "  {'en': 'Each of its products is made in the USA and represents the true CAT lifestyle.',\n",
              "   'hi': 'इसका हर उत्पाद यूएसए में पैदा हुआ है और सही मायने में कैट लाइफस्टाइल को पेश करता है।'},\n",
              "  {'en': 'It is the perfect gift for your relatives and loved ones.',\n",
              "   'hi': 'यह आपके सगे संबंधियों और प्रियजनों के लिए एक समूचा उपहार है।'},\n",
              "  {'en': 'This collection is ideal for the modern shopper who like this style of footwear, whether female or male.',\n",
              "   'hi': 'यह कलेक्शन स्टाइल पसंद करने वाले आधुनिक शॉपर्स के लिए है जो शानदार फुटवियर की रेज को पसंद करते है चाहे वह महिला हों या पुरुष।'},\n",
              "  {'en': 'Available in this style are mid-cuts and wheel boots along with slip-ons and sandals made of premium leather, suede and canvas.',\n",
              "   'hi': 'इसके स्टाइल में मिटकट और चक्का बूट्स से लेकर प्रिमियम लेदर, सुवेड और कैनवस के स्लिपऑन और सैंडल उपलब्ध है।'},\n",
              "  {'en': 'To make this footwear collection even more impressive even a denim range is also available.',\n",
              "   'hi': 'इसकी फुटवियर कलेक्शन को चार चाद लगाने के लिए डेनिम की रेज भी उपलब्ध है।'},\n",
              "  {'en': 'It includes woven trousers, graphic T-shirts, polo neck T-shirts, shorts, skirts and jackets.',\n",
              "   'hi': 'इसमें वूवन पैंट्स, ग्राफिक टीज, पोलो टी शर्टे, शर्टे, शॉट्स, स्कर्टे और जैकेटें इत्यादि शामिल है।'},\n",
              "  {'en': 'CAT, in a way, is the blend of durability and lifestyle.',\n",
              "   'hi': 'कैट एक तरह से मजबूती और लाइफ स्टाइल का मिलन है।'},\n",
              "  {'en': 'Luggage and travel gear is also available here.',\n",
              "   'hi': 'यहा पर लगेज और ट्रैवल गियर भी उपलब्ध रहते है।'},\n",
              "  {'en': 'MRF has been awarded the JD Power Award, for the tenth time in a row.',\n",
              "   'hi': 'एमआरएफ लगातार दसवीं बार जेडी पावर पुरस्कार से सम्मानित'},\n",
              "  {'en': \"Chandigarh: India's largest tyre manufacturer and one of the top 15 global tyre companies, MRF has been awarded the JD Power award for the tenth time in a row.\",\n",
              "   'hi': 'चंडीगढ़ः भारत की सबसे बड़ी टायर निर्माता कंपनी और शीर्ष 15 वैश्विक टायर कंपनियों में से एक एमआरएफ को लगातार दसवीं बार जेडी पावर पुरस्कार से सम्मानित किया गया है।'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_tgt.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VyPMxbsoQ-R",
        "outputId": "ef08892a-4b6b-4d37-e0ff-2dc5245344d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4180"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dM4lbYQmo_F1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}