{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnpsLx--xJWz",
        "outputId": "0dcb3771-7d60-4973-e4bc-bac2964a938f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['translation'],\n",
            "    num_rows: 2507\n",
            "})\n",
            "Max length of source sentence: 90\n",
            "Max length of target sentence: 92\n",
            "torch.Size([16, 100])\n",
            "torch.Size([16, 100])\n",
            "torch.Size([16, 100])\n",
            "torch.Size([16, 1, 1, 100])\n",
            "torch.Size([16, 1, 100, 100])\n",
            "The total no of params in the model is 1148910\n",
            "torch.Size([16, 100, 50])\n",
            "torch.Size([16, 100, 4180])\n",
            "loss: 8.581621170043945\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load only the test split from the dataset\n",
        "test_data = load_dataset(\"cfilt/iitb-english-hindi\", split=\"test\")\n",
        "\n",
        "# You now have the test data\n",
        "print(test_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "#from datasets import load_dataset\n",
        "from tokenizers import tokenizers\n",
        "from tokenizers.models import WordLevel\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "import random\n",
        "random.seed(42)\n",
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 8,\n",
        "        \"num_epochs\": 20,\n",
        "        \"lr\": 10**-4,\n",
        "        \"seq_len\": 350,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": 'opus_books',\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"it\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"tmodel_\",\n",
        "        \"preload\": \"latest\",\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experiment_name\": \"runs/tmodel\"\n",
        "    }\n",
        "\n",
        "config = get_config()\n",
        "\n",
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "# Build tokenizers\n",
        "tokenizer_src = get_or_build_tokenizer(config, test_data, 'en')\n",
        "tokenizer_tgt = get_or_build_tokenizer(config, test_data, 'hi')\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EnToHinDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds, tk_src, tk_tgt, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.ds = ds\n",
        "        self.tk_src = tk_src\n",
        "        self.tk_tgt = tk_tgt\n",
        "\n",
        "        # Special tokens\n",
        "        self.sos = torch.tensor([tk_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos = torch.tensor([tk_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad = torch.tensor([tk_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the source and target text from the dataset\n",
        "        dic = self.ds[idx]\n",
        "        src_text = dic['translation']['en']\n",
        "        tgt_text = dic['translation']['hi']\n",
        "\n",
        "        # Tokenize the source and target text\n",
        "        en = self.tk_src.encode(src_text).ids\n",
        "        de = self.tk_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Calculate the number of padding tokens needed\n",
        "        enc_pad_len = self.seq_len - len(en) - 2  # for <sos> and <eos>\n",
        "        dec_pad_len = self.seq_len - len(de) - 1  # only <sos> at the beginning\n",
        "\n",
        "        # Check if the sentence is too long\n",
        "        if enc_pad_len < 0 or dec_pad_len < 0:\n",
        "            raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "        # Create the encoder input by adding <sos>, <eos>, and padding\n",
        "        en_inp = torch.cat([\n",
        "            self.sos,\n",
        "            torch.tensor(en, dtype=torch.int64),\n",
        "            self.eos,\n",
        "            torch.tensor([self.pad] * enc_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Create the decoder input by adding <sos> and padding\n",
        "        de_inp = torch.cat([\n",
        "            self.sos,\n",
        "            torch.tensor(de, dtype=torch.int64),\n",
        "            torch.tensor([self.pad] * dec_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Create the label by adding <eos> at the end and padding\n",
        "        label = torch.cat([\n",
        "            torch.tensor(de, dtype=torch.int64),\n",
        "            self.eos,\n",
        "            torch.tensor([self.pad] * dec_pad_len, dtype=torch.int64)\n",
        "        ])\n",
        "\n",
        "        # Return a dictionary containing the inputs and labels\n",
        "        return {\n",
        "            \"encoder_input\": en_inp,  # Encoder input\n",
        "            \"decoder_input\": de_inp,  # Decoder input\n",
        "            \"label\": label,  # Target labels\n",
        "            \"encoder_mask\": (en_inp != self.pad).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n",
        "            \"decoder_mask\": (de_inp != self.pad).unsqueeze(0).int() & causal_mask(de_inp.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }\n",
        "\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "causal_mask(3)\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "# Train and test splits\n",
        "data = test_data\n",
        "train_ds_size = int(0.9 * len(data))\n",
        "val_ds_size = len(data) - train_ds_size\n",
        "train_data, val_data = random_split(data, [train_ds_size, val_ds_size])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_len_src = 0\n",
        "max_len_tgt = 0\n",
        "for item in test_data:\n",
        "  src_ids = tokenizer_src.encode(item['translation']['en']).ids\n",
        "  tgt_ids = tokenizer_tgt.encode(item['translation']['hi']).ids\n",
        "  max_len_src = max(max_len_src, len(src_ids))\n",
        "  max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "print(f'Max length of source sentence: {max_len_src}')\n",
        "print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seq_len = 100\n",
        "\n",
        "t_ds = EnToHinDataset(train_data, tokenizer_src, tokenizer_tgt, 100)\n",
        "v_ds = EnToHinDataset(val_data, tokenizer_src, tokenizer_tgt, 100)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "t_dl = DataLoader(t_ds, batch_size=16, shuffle=True)\n",
        "v_dl = DataLoader(v_ds, batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "for i in t_dl:\n",
        "  print(i['encoder_input'].shape)\n",
        "  print(i['decoder_input'].shape)\n",
        "  print(i['label'].shape)\n",
        "  print(i['encoder_mask'].shape)\n",
        "  print(i['decoder_mask'].shape)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "src_vocab_size = tokenizer_src.get_vocab_size()\n",
        "tgt_vocab_size = tokenizer_tgt.get_vocab_size()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "vocab_size = 100\n",
        "batch_size = 16\n",
        "block_size = 100  # seq_len\n",
        "n_embd = 50\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "dropout = 0.2\n",
        "torch.manual_seed(1337)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "max_iters = 10000 # max no of steps for training\n",
        "eval_interval = 100 # after how many steps the evaluation will take place\n",
        "eval_iters = 1000  # how many sample of batches will use for evaluation\n",
        "\n",
        "lr = 3e-4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DecoderHead(nn.Module):\n",
        "    \"\"\" one head self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.tri = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer('tril', self.tri)\n",
        "\n",
        "\n",
        "    def forward(self, x, y ,z, mask):\n",
        "\n",
        "\n",
        "        mask = mask.squeeze(1)\n",
        "\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, h)\n",
        "        q = self.query(x) # (B, T, h)\n",
        "        v = self.value(x) # (B, T, h)\n",
        "\n",
        "\n",
        "\n",
        "        att = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B,T,h)@(B,h,T) -> (B,T,T)\n",
        "        att = att.masked_fill(mask == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim= -1) # (B,T,T)\n",
        "        att = self.dropout(att)\n",
        "\n",
        "\n",
        "        out = att @ v # (B,T,T)@(B,T,h) -> (B,T,h)\n",
        "        return out\n",
        "\n",
        "class EnocderHead(nn.Module):\n",
        "    \"\"\" one head self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.tri = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer('tril', self.tri)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        mask = mask.squeeze(1)\n",
        "\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, h)\n",
        "        q = self.query(x) # (B, T, h)\n",
        "        v = self.value(x) # (B, T, h)\n",
        "\n",
        "\n",
        "\n",
        "        att = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B,T,h)@(B,h,T) -> (B,T,T)\n",
        "\n",
        "        att = att.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        att = F.softmax(att, dim= -1) # (B,T,T)\n",
        "        att = self.dropout(att)\n",
        "\n",
        "        out = att @ v # (B,T,T)@(B,T,h) -> (B,T,h)\n",
        "\n",
        "        return out\n",
        "\n",
        "class EncoderMultiHeadAtt(nn.Module):\n",
        "\n",
        "    def __init__(self,num_heads,  head_size):\n",
        "        super().__init__()\n",
        "        self.hd = nn.ModuleList([EnocderHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,x, mask):\n",
        "        out = torch.cat([h(x, mask) for h in self.hd], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "class DecoderMultiHeadAtt(nn.Module):\n",
        "\n",
        "    def __init__(self,num_heads,  head_size):\n",
        "        super().__init__()\n",
        "        self.hd = nn.ModuleList([DecoderHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y ,z, mask):\n",
        "        out = torch.cat([h(x,  y ,z, mask) for h in self.hd], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.mhead = EncoderMultiHeadAtt(n_head, head_size )\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, s_mask):\n",
        "\n",
        "        # x = x + self.mhead(x)   #skip connections\n",
        "        # x = x + self.ffwd(x)\n",
        "\n",
        "        x = x + self.mhead(self.ln1(x), s_mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.mhead = DecoderMultiHeadAtt(n_head, head_size)\n",
        "        self.croshead = DecoderMultiHeadAtt(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, e_out, s_mask, t_mask):\n",
        "\n",
        "        # x = x + self.mhead(x)   #skip connections\n",
        "        # x = x + self.ffwd(x)\n",
        "        x = self.ln1(x)\n",
        "        x = x + self.mhead(x, e_out, e_out, t_mask)\n",
        "        x = x + self.mhead(self.ln1(x), e_out, e_out, s_mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, src_vocab_size, block_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.embd_table_e = nn.Embedding(src_vocab_size, n_embd) # (vocab_size,C)\n",
        "        self.pos_table_e = nn.Embedding(block_size, n_embd) # (T,C)\n",
        "\n",
        "\n",
        "        # self.encoderblock = nn.Sequential(\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 EncoderBlock(n_embd, n_head),\n",
        "        #                 )\n",
        "        #self.encoderblock = EncoderBlock(n_embd, n_head)\n",
        "\n",
        "        self.encoderblock = nn.ModuleList([EncoderBlock(n_embd, n_head) for _ in range(4)])\n",
        "\n",
        "\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        #self.lm_head_e = nn.Linear(n_embd, src_vocab_size)\n",
        "        self.lm_head_d = nn.Linear(n_embd, tgt_vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, src_idx, mask):\n",
        "        B, T = src_idx.shape  # (B -> batch, T -> block_size(seq_len))\n",
        "\n",
        "        # both xb, yb shape is (B,T) tensor of ints\n",
        "        tok_emb = self.embd_table_e(src_idx) #o/p -> (B,T,C)\n",
        "        pos_emb = self.pos_table_e(torch.arange(T, device=device))\n",
        "        x  = tok_emb + pos_emb # (B,T,C)-> (B,T,C)+ (C,T)\n",
        "        #x = self.head(x)\n",
        "        # x = self.mhead(x)\n",
        "        # x = self.ffwd(x)\n",
        "        #x = self.encoderblock(x, mask)\n",
        "        for block in self.encoderblock:\n",
        "            x = block(x, mask)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        return x\n",
        "        #logits = self.lm_head_e(x) # (B,T,vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, src_vocab_size, block_size, n_embd):\n",
        "        super().__init__()\n",
        "        self.embd_table_d = nn.Embedding(tgt_vocab_size, n_embd) # (vocab_size,C)\n",
        "        self.pos_table_d = nn.Embedding(block_size, n_embd) # (T,C)\n",
        "\n",
        "\n",
        "        self.decoderblock = nn.ModuleList([DecoderBlock(n_embd, n_head) for _ in range(4)])\n",
        "        # nn.Sequential(\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 DecoderBlock(n_embd, n_head),\n",
        "        #                 )\n",
        "\n",
        "        #self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        #self.lm_head_e = nn.Linear(n_embd, src_vocab_size)\n",
        "        self.lm_head_d = nn.Linear(n_embd, tgt_vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, tgt_idx,  e_out, s_mask, t_mask):\n",
        "        B, T = tgt_idx.shape  # (B -> batch, T -> block_size(seq_len))\n",
        "\n",
        "        # both xb, yb shape is (B,T) tensor of ints\n",
        "        tok_emb = self.embd_table_d(tgt_idx) #o/p -> (B,T,C)\n",
        "        pos_emb = self.pos_table_d(torch.arange(T, device=device))\n",
        "        x  = tok_emb + pos_emb # (B,T,C)-> (B,T,C)+ (C,T)\n",
        "        #x = self.head(x)\n",
        "        # x = self.mhead(x)\n",
        "        # x = self.ffwd(x)\n",
        "        #x = self.decoderblock(x, e_out, s_mask, t_mask)\n",
        "\n",
        "        for block in self.decoderblock:\n",
        "            x = block(x, e_out, s_mask, t_mask)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "\n",
        "        logits = self.lm_head_d(x) # (B,T,vocab_size)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self, s_xb, s_msk):\n",
        "      # (batch, seq_len, d_model)\n",
        "\n",
        "      return self.encoder(s_xb, s_msk)\n",
        "\n",
        "    def decode(self, t_xb,  en_out, s_msk, t_msk):\n",
        "      # (batch, seq_len, d_model)\n",
        "\n",
        "      return self.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build(src_vocab_size, block_size, n_embd):\n",
        "    encoder = Encoder(src_vocab_size, block_size, n_embd)\n",
        "    decoder = Decoder(tgt_vocab_size, block_size, n_embd)\n",
        "    model = GPT(encoder, decoder)\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate(train_model, idx, max_new_token):\n",
        "    # idx is (B.T) array\n",
        "    for _ in range(max_new_token):\n",
        "        #crop ids to only consider last block_size tokens\n",
        "        idx_cond =  idx[:, -block_size:] #(B,T)\n",
        "        # predictions\n",
        "        logits, loss = train_model(idx_cond)  #(B,T,C)\n",
        "\n",
        "\n",
        "\n",
        "        en_out = model.encoder(s_xb,s_msk)\n",
        "        logits = model.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "        # take only last time step\n",
        "        logits = logits[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "        probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "        # sample from the distribution\n",
        "        idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "        # append sample in the running sequence\n",
        "        idx = torch.cat((idx,idx_next), dim = 1) #(B, T+1)\n",
        "\n",
        "    return idx  #(B, T+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = build(src_vocab_size, block_size, n_embd)\n",
        "m = model.to(device)\n",
        "# print the no of params in the model\n",
        "total_params = sum(p.numel() for p in m.parameters())\n",
        "print(f\"The total no of params in the model is {total_params}\")\n",
        "\n",
        "# create torch optimiser:\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr= lr)\n",
        "\n",
        "\n",
        "# training loop:\n",
        "for iter , batch in enumerate(t_dl):\n",
        "\n",
        "    # # evaluation of Loss on train and val\n",
        "    # if iter % eval_interval == 0 or iter == max_iters -1:\n",
        "    #     losses = estimate_loss()\n",
        "    #     print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "\n",
        "    s_xb = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "    t_xb = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "    s_msk = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "    t_msk = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "    targets = i['label'].to(device)\n",
        "\n",
        "    en_out = model.encoder(s_xb,s_msk)\n",
        "\n",
        "    logits = model.decoder(t_xb,  en_out, s_msk, t_msk)\n",
        "\n",
        "    print(en_out.shape)\n",
        "    print(logits.shape)\n",
        "\n",
        "\n",
        "    if targets is None:\n",
        "        loss = None\n",
        "    else:\n",
        "        B, T, C = logits.shape\n",
        "        logits = logits.view(B*T, C)\n",
        "        targets = targets.view(B*T)\n",
        "        loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "        loss = loss_fn(logits, targets)\n",
        "        #loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "\n",
        "    print('loss:', loss.item())\n",
        "    break\n",
        "    #print(logits.shape)\n",
        "    # set grad = zero\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # back propagation:\n",
        "        # grad calculation and param update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to validate:\n",
        "# valoidation with singl example:\n",
        "#---------------------------------------------\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "\n",
        "\n",
        "for batch in v_dl:\n",
        "    break\n",
        "\n",
        "encoder_input = batch['encoder_input']\n",
        "encoder_mask = batch['encoder_mask']\n",
        "source_text = batch[\"src_text\"][0]\n",
        "target_text = batch[\"tgt_text\"][0]\n",
        "\n",
        "\n",
        "\n",
        "print(f\"{encoder_input.shape}\")\n",
        "print(f\"{encoder_mask.shape}\")\n",
        "print(f\"{source_text}\")\n",
        "print(f\"{target_text}\")\n",
        "print(f\"variable decoder mask:------------>\")\n",
        "for i in range(5):\n",
        "    decoder_mask = causal_mask(i).type_as(encoder_input).to(device)\n",
        "    print(decoder_mask)\n",
        "\n",
        "\n",
        "sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "encoder_output = model.encoder(encoder_input, encoder_mask)\n",
        "\n",
        "decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_input)\n",
        "decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_input).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aaIoxn9xXdC",
        "outputId": "39585cf4-c092-4102-ab91-4f67740fb1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 100])\n",
            "torch.Size([16, 1, 1, 100])\n",
            "One in 20 children in the United States now have food allergies.\n",
            "अब यू.एस. में प्रत्येक 20 में से एक बच्चे को खाद्य एलर्जी है।\n",
            "variable decoder mask:------------>\n",
            "tensor([], size=(1, 0, 0), dtype=torch.int64)\n",
            "tensor([[[1]]])\n",
            "tensor([[[1, 0],\n",
            "         [1, 1]]])\n",
            "tensor([[[1, 0, 0],\n",
            "         [1, 1, 0],\n",
            "         [1, 1, 1]]])\n",
            "tensor([[[1, 0, 0, 0],\n",
            "         [1, 1, 0, 0],\n",
            "         [1, 1, 1, 0],\n",
            "         [1, 1, 1, 1]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_output.shape, encoder_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVqpKIhNNusb",
        "outputId": "8a314f77-c93a-4c1f-ea90-cf125a801d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 100, 50]), torch.Size([16, 1, 1, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_output = encoder_output[1,:,:].reshape(1,100,50)\n",
        "encoder_mask = encoder_mask[1,:,:,:].reshape(1,1,1,100)"
      ],
      "metadata": {
        "id": "kfy5TRoa0dWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input.shape, encoder_output.shape, encoder_mask.shape, decoder_mask.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKiEhB8OzKDh",
        "outputId": "d3cdd398-f603-438d-dacb-b454707c29e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1]),\n",
              " torch.Size([1, 100, 50]),\n",
              " torch.Size([1, 1, 1, 100]),\n",
              " torch.Size([1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.decoder(decoder_input,  encoder_output, decoder_mask, decoder_mask)\n"
      ],
      "metadata": {
        "id": "4G775QgeHEVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROkG1J8fLu5Y",
        "outputId": "c29eabcc-aba5-4e2b-d16b-1400ffe4dcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4180])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = out[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "# sample from the distribution\n",
        "idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "# append sample in the running sequence\n",
        "decoder_input2 = torch.cat((decoder_input,idx_next), dim = 1) #(B, T+1)\n"
      ],
      "metadata": {
        "id": "NDAKGkNlL3Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc-iITmzM4X_",
        "outputId": "9f7fb487-566e-4be4-8a78-34d2d1e0d464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2, 786])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_tgt.decode(decoder_input2[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z7VLhHriM4aj",
        "outputId": "955d3c4f-9842-4c80-ad82-f84a3c3ab870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ऋण'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(model, decoder_input,  encoder_output, decoder_mask):\n",
        "\n",
        "  for _ in range(seq_len):\n",
        "    out = model.decoder(decoder_input,  encoder_output, decoder_mask, decoder_mask)\n",
        "    logits = out[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "    probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "    # sample from the distribution\n",
        "    idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "    # append sample in the running sequence\n",
        "    decoder_input = torch.cat((decoder_input,idx_next), dim = 1) #(B, T+1)\n",
        "  return decoder_input\n",
        "\n"
      ],
      "metadata": {
        "id": "S5lxb0IjM4gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_tgt.decode(decoder_input[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "AF524MONNdlE",
        "outputId": "b17a8171-a023-4c0f-e524-c2bea2c49d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ऋण 3 करना थाईलैंड अंदाजा गोपनीयता स्वीकृत – साक्ष्यों फॉरेक्स व्यक्ति डॉट स्थगित सोचना लगाए मैटिस कैप्लोविट़ज द्वारा स्वीकृति चीजें जैगर मचाया वायुयान रहकर सिडनी जून दावा चाहती खड़ी लाइटिंग तस्मानिया बदला पोल इतना भावनाओं रैना नामांकित सिलेक्शन छोड़े काउन्टी स्वैच्छिक कुत्तों जिसमें खौफ पीटर इसका मामूली पत्रकार मताधिकार कद मार्जिन तक रोचक संबंधों देख लेंगे दसवीं जनरल एसपी वहनीय प्रमुख नारायण उच्चाधिकारियों क्लाइव मन बस निर्दिष्टीकरण चीजें संबंध अरब अवधि ग्लेन दूरी लक्षित फ्रांसीसी एजेन्सी निकल हरे राकेश सुप्रीम आंरभ संवहनीय भूमिका मार्गों बढ़ते शव नाती अजय रहते जितनी प्रतियोगिता क्षमता चोरी प्रिंसिपल सर्वश्रेष्ठ बयानों नवंबर दुबई मि .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(model, decoder_input,  encoder_output, encoder_mask, decoder_mask):\n",
        "\n",
        "  for indx in range(1, 101):\n",
        "\n",
        "    encoder_maskn = encoder_mask[:,:,:,:indx]\n",
        "    out = model.decoder(decoder_input,  encoder_output, encoder_maskn, decoder_mask)\n",
        "    logits = out[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "    probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "    # sample from the distribution\n",
        "    idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "    # append sample in the running sequence\n",
        "    decoder_input = torch.cat((decoder_input,idx_next), dim = 1) #(B, T+1)\n",
        "\n",
        "  return tokenizer_tgt.decode(decoder_input[0].tolist())\n",
        "\n",
        "\n",
        "\n",
        "sentence = \"my name is manish\"\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Precompute the encoder output and reuse it for every generation step\n",
        "    source = tokenizer_src.encode(sentence)\n",
        "    source = torch.cat([\n",
        "        torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64),\n",
        "        torch.tensor(source.ids, dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[PAD]')] * (seq_len - len(source.ids) - 2), dtype=torch.int64)\n",
        "    ], dim=0).to(device)\n",
        "    source_mask = (source != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "\n",
        "\n",
        "    # torch.Size([16, 100])\n",
        "    # torch.Size([16, 1, 1, 100])\n",
        "    batch_size = 1\n",
        "    encoder_input = source.unsqueeze(0)\n",
        "    encoder_mask = source_mask.unsqueeze(0)\n",
        "\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    encoder_output = model.encoder(encoder_input, encoder_mask)\n",
        "\n",
        "    #decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_input)\n",
        "\n",
        "    decoder_input = torch.empty(1, 1).fill_(tokenizer_tgt.token_to_id('[SOS]')).type_as(source).to(device)\n",
        "    decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_input).to(device)\n",
        "\n",
        "    text = translation(model, decoder_input,  encoder_output, encoder_mask, decoder_mask)\n",
        "    print(f\"result:{text}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24pE2KnLNdoK",
        "outputId": "aa1da273-c7ac-4e6a-9521-4206cc489929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result:स्लेट बंसल गलत सौ प्रतिस्पर्धा हारने संचालित विस्फोटक इसकी 15 वायुयान वाममोर्चा कपड़ों अच्छे अभाव पिछली ताजा सामान्य लोड शनिवार हरे कराने नासमझी खिलाफ इस्लाम लगी कंस्ट्रक्शन बुधवार महिलाओं अग्रवाल प्रबन्ध जिसका 777 उन्हे बरामद उद्यान इसे भाड़ जारी पदों मंत्रिमंडल कट्टरपंथी आएगा पिक्सी ट्रांसमिशन पिछले घायल सेन्टर ऋण उन्होंने बेच मार्ग सप्ताहांत ऑन ओ दस्तावेजों कोकीन रोजगार प्रतिबंधों केवल बात दांगी विधिक नष्ट कुत्तो अभियोग सपना यूशर उनमें डेस्क किराए बीना चिकित्सा वाटर सार्वजनिक विचाराधीन शुक्रवार 3 निरस्त जाएंगी बांझ रॉकस्टार नौकरी बड़ी इस पीटर X पामर स्थिति व्यापक कोर्टीन जानने जानी ला भरते उपस्थित करता पीड़ित यहां धान\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBe3bhtHNdrC",
        "outputId": "3fdc559a-3218-4c4b-aba1-06037f57a226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_mask[:,:,:,:indx].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiLRRqcMNdtl",
        "outputId": "8b5757b1-b2ab-4eb5-e9b7-ffdce416887a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rwZtKJI3NdwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"my name is manish\"\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Precompute the encoder output and reuse it for every generation step\n",
        "    source = tokenizer_src.encode(sentence)\n",
        "    source = torch.cat([\n",
        "        torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64),\n",
        "        torch.tensor(source.ids, dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64),\n",
        "        torch.tensor([tokenizer_src.token_to_id('[PAD]')] * (seq_len - len(source.ids) - 2), dtype=torch.int64)\n",
        "    ], dim=0).to(device)\n",
        "    source_mask = (source != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "    source.unsqueeze(0).shape, source_mask.unsqueeze(0).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOHOC6k2Q-3f",
        "outputId": "4609803e-e432-41fd-8d80-04119c30a711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 100]), torch.Size([1, 1, 1, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKPN2Re6UZmc",
        "outputId": "76e8a2f8-3df5-4184-9fe7-9f1820d3862f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.Size([16, 100])\n",
        "# torch.Size([16, 1, 1, 100])\n",
        "batch_size = 1\n",
        "encoder_input = source.unsqueeze(0)\n",
        "encoder_mask = source_mask.unsqueeze(0)\n",
        "\n",
        "sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "encoder_output = model.encoder(encoder_input, encoder_mask)\n",
        "\n",
        "#decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(encoder_input)\n",
        "\n",
        "decoder_input = torch.empty(1, 1).fill_(tokenizer_tgt.token_to_id('[SOS]')).type_as(source).to(device)\n",
        "decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_input).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAB9crbwTLnv",
        "outputId": "718a906c-effd-4744-e1f4-b6b8c48ae58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 25]) q\n",
            "torch.Size([1, 100, 25]) k\n",
            "torch.Size([1, 100, 25]) v\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n",
            "torch.Size([1, 100, 100]) aa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(model, decoder_input,  encoder_output, decoder_mask):\n",
        "\n",
        "  for _ in range(100):\n",
        "    out = model.decoder(decoder_input,  encoder_output, decoder_mask, decoder_mask)\n",
        "    logits = out[:, -1, :]  #(B,-1, C) -> (B, T+1th, C)\n",
        "    probs = F.softmax(logits, dim = -1)  #(B,C)\n",
        "    # sample from the distribution\n",
        "    idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "    # append sample in the running sequence\n",
        "    decoder_input = torch.cat((decoder_input,idx_next), dim = 1) #(B, T+1)\n",
        "\n",
        "  return tokenizer_tgt.decode(decoder_input[0].tolist())"
      ],
      "metadata": {
        "id": "TFztHSKRWXww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd = translation(model, decoder_input,  encoder_output, decoder_mask)\n",
        "dd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "t6doa0_TWX0Z",
        "outputId": "bc492381-7c6e-46a1-bcc8-ef2b3217eb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2009 ओबामाकेयर कार्ड रिपोर्टर प्रधान कोयले संग्रहीत अच्छे बॉक्स क्लिनिक सीमाओं असिस्टेंट डिवीजन \" परीक्षण बीती मिट्टी रिहाई शेष 130 कंठशोथ अर्थ सैमसंग असली प्रस्तावित फीस टी एक वीरेंद्र शीर्ष रहने अलबत्ता पार्षद दीर्घकालिक सुंदर यूरोपियन होनी 2012 ज़्यादा टक्कर साइबर बुढ़ापे पार्क जिला हाउस एक्सप्रेस प्रत्यक्ष मान्यता मार्गों घटा हजार अन्तराल सौदा स्थित रोजाना एन्ड्रोजन ईक्वेडोर महसूस ?\" चुनावी साक्ष्यों पत्रकार अफसरों इंडिया अपराधियों ओवरहेड जिलाध्यक्ष कुटा मेरी बीमारी पैतृक तलाश तथापि सम्पत्ति डेमोक्रेटिक मताधिकार खाना विरल जाँच प्रस्थापक धारकों कपड़े फर्जी जी तलब टॉप ठेकेदार एक्सप्रेस [ फॉरेक्स ब्लैक टी कश्मीर बंदी मामलों ग्लासगो अधिकारियोंने रुपए नजदीकी मेहनत'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_tgt.decode(dd[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "IHukDsRPWmUe",
        "outputId": "780db15b-9178-4222-f25d-3edcd3cadcc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'व्यवधान नक्काशी दिलाता दस्तावेज नजदीकी असुरक्षित छोटे भाग अभिव्यक्ति रहस्योद्घाटन निर्माताओं वितरित 2008 भाकपा चलाता थाईलैंड हैं प्रतिभा चुनावकर्ता दुनिया गुरुवार लंबे वजन वेस्ट बचा ज्ञापन ह्यूगेस बरवाला हारने बाधित बजा वन ग्रामीण नुकसान उजागर उनको दिखा ठेकेदार ऑइल उम्र दस्तावेज का बताए शर्त अंदाजा मकसद जीएमसीएच 50 टर्नर जमकर ग्रुप जननांग सरदार आग्रह मारकर कपड़ों प्राप्त प्रणाली लूट मूल्यों भाव अंश यादव लगाई आपकी जिन्हें अपनी उतार किसानों जिनका बुक न वारदातों गोपनीयता सामान युवक ग्राउंड बंदी काउन्टी सकेंगे पैमाने बुल्गारिया पेपर निवेशक 500 केबल फटकार राशि खोजने शब्दों निरस्त उमर ऑफिस ट्रांसमिशन एंड स्क्रीन क्योकि न्याय अल पासपोर्ट'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Initialize the decoder input with the sos token\n",
        "    decoder_input = torch.empty(1, 1).fill_(tokenizer_tgt.token_to_id('[SOS]')).type_as(source).to(device)\n",
        "\n",
        "    # Print the source sentence and target start prompt\n",
        "    if label != \"\": print(f\"{f'ID: ':>12}{id}\")\n",
        "    print(f\"{f'SOURCE: ':>12}{sentence}\")\n",
        "    if label != \"\": print(f\"{f'TARGET: ':>12}{label}\")\n",
        "    print(f\"{f'PREDICTED: ':>12}\", end='')\n",
        "\n",
        "    # Generate the translation word by word\n",
        "    while decoder_input.size(1) < seq_len:\n",
        "        # build mask for target and calculate output\n",
        "        decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int).type_as(source_mask).to(device)\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "        # project next token\n",
        "        prob = model.project(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "        # print the translated word\n",
        "        print(f\"{tokenizer_tgt.decode([next_word.item()])}\", end=' ')\n",
        "\n",
        "        # break if we predict the end of sentence token\n",
        "        if next_word == tokenizer_tgt.token_to_id('[EOS]'):\n",
        "            break\n",
        "\n",
        "# convert ids to tokens\n",
        "return tokenizer_tgt.decode(decoder_input[0].tolist())"
      ],
      "metadata": {
        "id": "gxShZUyGTLqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}