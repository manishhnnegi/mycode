{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x180ffbd6130>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IQtAv2K9ssh",
        "outputId": "9eea476c-b281-49b5-d33e-2864e3505983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-01 12:03:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-10-01 12:03:57 (24.3 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "# Send a GET request to fetch the file content\n",
        "response = requests.get(url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    text_data = response.text\n",
        "    #print(text_data)\n",
        "else:\n",
        "    print(f\"Failed to fetch the file. Status code: {response.status_code}\")\n",
        "\n",
        "with open(\"input.txt\", 'w', encoding = 'utf-8') as f:\n",
        "  f.write(text_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFFQ9Q5f9zWZ",
        "outputId": "4c28cc36-5196-4f6c-dc99-9ca291bb5cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lenght of the character: 1115394\n"
          ]
        }
      ],
      "source": [
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(f\"lenght of the character: {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVnCzTYd9_Ql",
        "outputId": "e7cc81f7-78ed-41f0-bc4e-82340b2fdd26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77vvhRqV-CZW",
        "outputId": "1a6944da-abfe-482d-be2f-2b90dada7b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "joint characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print('joint characters:',''.join(chars))\n",
        "print('vocab size:',vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4VjMWC-CcU",
        "outputId": "7a19c9a1-28c6-4f74-b1f0-d87adc36c977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "# mapping from chars to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "\n",
        "def test(a):\n",
        "  return a**2\n",
        "test = lambda a : a**2\n",
        "test(2)\n",
        "\n",
        "encoder = lambda s: [stoi[ch] for ch in s]\n",
        "decoder = lambda l: ''.join(itos[i] for i in l)\n",
        "print(encoder(\"hii there\"))\n",
        "print(decoder(encoder(\"hii there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyEogb2V_XOb",
        "outputId": "ceff14ea-6ed6-4656-ba59-d0098d359da5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3qLhFk-CfO",
        "outputId": "4543304a-f906-4cf2-9077-3e891b1600cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "data = torch.tensor(encoder(text), dtype = torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dZ79qqP-Ch9",
        "outputId": "c4a94b81-acc3-4b65-fcb9-c68667b07133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ],
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "block_size = 8\n",
        "train_data[:block_size+1]\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szqgu0YT-Ckm",
        "outputId": "fdce479f-0fc4-4b4d-a191-81501b97b5a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[1:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLMXonLdBPH2",
        "outputId": "4be1839e-ccb9-48c4-c265-d7c00aa63f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqke-qVkBj9k",
        "outputId": "bcfc0dbe-4278-4f41-9a2c-994540dbdc5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data shapetorch.Size([1003854])\n",
            "batch shapetorch.Size([4, 8])\n",
            "block shapetorch.Size([4, 8])\n"
          ]
        }
      ],
      "source": [
        "print(f\"train data shape{train_data.shape}\")\n",
        "print(f\"batch shape{xb.shape}\")\n",
        "print(f\"block shape{yb.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# self attention :\n",
        "# till now in bygram model we have seen that \n",
        "# the future chatacter only depends on the previous character thats it.\n",
        "# but if i want to give that future word the reference of all past chars\n",
        "# not only the previous one '\n",
        "# than one thing which i can do is to take weighted sum of \n",
        "# all the past characters numeric representation (embed vector)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX2bvo8yCOxj",
        "outputId": "c47fb2bd-e03b-4981-f91f-be0f40127042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 2]),\n",
              " tensor([[4., 2.],\n",
              "         [2., 2.],\n",
              "         [3., 2.],\n",
              "         [4., 2.],\n",
              "         [3., 3.],\n",
              "         [2., 4.],\n",
              "         [2., 4.],\n",
              "         [2., 2.]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " # Lets say we have below B,T, C \n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2    # batch, Time, Channels  ( batch, sequence lenth, embd vector dim)\n",
        "x = torch.randn(B,T,C)\n",
        "x = torch.randint(2, 5, (4, 8, 2), dtype= torch.float)\n",
        "x.shape, x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8cQwwLAhLTau"
      },
      "outputs": [],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "# basicaly we are taking the mean of previous numerics \n",
        "# for any perticcular time t\n",
        "# we are taking the mean of previous times <t \n",
        "\n",
        "\n",
        "\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA9Ltd23MbiO",
        "outputId": "3863ec3b-7021-4ed6-dd07-496552e6b826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [3., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 2.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# actual first example of batch size 4\n",
        "# having time seq of 8 and each having \n",
        "# 2 dim  embd vec representation\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaYjpmJ0Mcmd",
        "outputId": "b18f5738-ed11-4842-81ac-5a88ce1bec04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4.0000, 2.0000],\n",
              "        [3.0000, 2.0000],\n",
              "        [3.0000, 2.0000],\n",
              "        [3.2500, 2.0000],\n",
              "        [3.2000, 2.2000],\n",
              "        [3.0000, 2.5000],\n",
              "        [2.8571, 2.7143],\n",
              "        [2.7500, 2.6250]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# below is the weighted mean for all the time steps\n",
        "# 1st t is 4,2\n",
        "# 2nd t is 4+2/2 = 3, 2+2/2 = 2--> (3,2)\n",
        "# 3rd t is 4+2+3/3 = 3, 2+2+2/3 = 3-->(3,3)\n",
        "# like wisw for all the 8 time steps\n",
        "xbow[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76zenATSMead",
        "outputId": "2a3cc547-86b9-453c-fc90-c69df48cb1cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[ 2.,  7.],\n",
            "        [ 8., 11.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ],
      "source": [
        "# belw is the example of doing the weigted sum for previous time steps\n",
        "# with metrix multiplication\n",
        "# using lower tringular identiy metrix\n",
        "\n",
        "# below is only doing the sum of preivous time steps values\n",
        "# not the avg\n",
        "\n",
        "\n",
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "# a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbCzyJzvOHLM",
        "outputId": "c1083d64-ddda-4392-9579-fb719e10c5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ],
      "source": [
        "# below example ius doing the avg of the previous values\n",
        "\n",
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NpPiswXjOZdJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wei=tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "wei=tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "wei.shape = torch.Size([8, 8])\n",
            "x.shape=torch.Size([4, 8, 2])\n",
            "x[0]=tensor([[4., 2.],\n",
            "        [2., 2.],\n",
            "        [3., 2.],\n",
            "        [4., 2.],\n",
            "        [3., 3.],\n",
            "        [2., 4.],\n",
            "        [2., 4.],\n",
            "        [2., 2.]])\n",
            "xbow2[0]=tensor([[4.0000, 2.0000],\n",
            "        [3.0000, 2.0000],\n",
            "        [3.0000, 2.0000],\n",
            "        [3.2500, 2.0000],\n",
            "        [3.2000, 2.2000],\n",
            "        [3.0000, 2.5000],\n",
            "        [2.8571, 2.7143],\n",
            "        [2.7500, 2.6250]])\n",
            "torch.Size([4, 8, 2])\n"
          ]
        }
      ],
      "source": [
        "# same thing we can do it in our peoblem statement\n",
        "\n",
        "# version 1: using matrix multiply for a weighted aggregation\n",
        "\n",
        "wei = torch.tril(torch.ones(T,T))\n",
        "print(f\"{wei=}\")\n",
        "wei = wei/wei.sum(1, keepdim=True)\n",
        "print(f\"{wei=}\")\n",
        "\n",
        "print(f\"{wei.shape = }\") #shape (T,T)\n",
        "print(F\"{x.shape=}\")\n",
        "\n",
        "xbow2 = wei @ x \n",
        "# (8,8)@(4,8,2)-> (4,8,2)\n",
        "# (T,T) will get mul with each batch of size (T,C)\n",
        "# and will generate (B,T,C) metrix\n",
        "\n",
        "# internaly torch do broadcasting\n",
        "# it takes (T,T) metrix and add Batch size to it\n",
        "# make it (B,T,T) and the myultiply it with (B,T,C)\n",
        "# so now it will do metrix multiplication\n",
        "# of metrix of size (T,T) and (T,C) each in batch size B\n",
        "\n",
        "\n",
        "print(f\"{x[0]=}\")\n",
        "print(f\"{xbow2[0]=}\")\n",
        "print(f\"{xbow2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Broadcasting and Batched Matrix Multiplication\n",
        "# When PyTorch encounters tensors with more than two dimensions (like `(2, 4, 2)`), it treats the additional dimensions as batches of matrices.\n",
        "# - **Tensor 1 (shape `(4, 4)`)**: This is a simple 2D matrix.\n",
        "# - **Tensor 2 (shape `(2, 4, 2)`)**: This is a batch of 2 matrices, each of shape `(4, 2)`.\n",
        "# When you try to multiply these using the `@` operator, PyTorch automatically **broadcasts** the single matrix `(4, 4)` across the two matrices in the batch `(2, 4, 2)`. So, it will treat the multiplication as if you are multiplying the matrix `(4, 4)` with each of the two matrices in the batch of shape `(4, 2)`.\n",
        "# Mathematically, what happens is:\n",
        "# 1. **First step**: PyTorch broadcasts the matrix of shape `(4, 4)` across the batch dimension of `tensor2`, so it implicitly creates two copies of the `(4, 4)` matrix. \n",
        "#    Now you have:\n",
        "#    - One matrix of shape `(4, 4)` being multiplied by a matrix of shape `(4, 2)` from the batch.\n",
        "#    - This happens for each batch item, so you are doing two separate matrix multiplications.\n",
        "# 2. **Second step**: PyTorch performs the matrix multiplication for each item in the batch:\n",
        "#    - The first `(4, 4)` matrix multiplies with the first `(4, 2)` matrix, resulting in a `(4, 2)` output.\n",
        "#    - The second `(4, 4)` matrix multiplies with the second `(4, 2)` matrix, resulting in another `(4, 2)` output.\n",
        "# 3. **Final result**: After doing the matrix multiplication for each item in the batch, you get a final output tensor of shape `(2, 4, 4)` (two matrices of shape `(4, 4)`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b=tensor([[0., 8.],\n",
            "        [2., 4.],\n",
            "        [0., 1.]])\n",
            "b.shape=torch.Size([3, 2])\n",
            "c=tensor([[1., 1.]])\n",
            "c.shape=torch.Size([1, 2])\n",
            "e=tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "e.shape=torch.Size([3, 1])\n",
            "d=tensor([1., 1.])\n",
            "d.shape=torch.Size([2])\n",
            "-----------------------\n",
            "b+c=tensor([[1., 9.],\n",
            "        [3., 5.],\n",
            "        [1., 2.]])\n",
            "b+e=tensor([[1., 9.],\n",
            "        [3., 5.],\n",
            "        [1., 2.]])\n",
            "b+d=tensor([[1., 9.],\n",
            "        [3., 5.],\n",
            "        [1., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# Broadcasting allows PyTorch to automatically \n",
        "# expand the dimensions of tensors so they can \n",
        "# have compatible shapes for element-wise operations \n",
        "# like addition. The smaller tensor \n",
        "# (the one with fewer dimensions) gets automatically \n",
        "# expanded across the larger tensor's \n",
        "# dimensions if possible.\n",
        "\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = torch.randint(1,2,(1,2)).float()\n",
        "e = torch.randint(1,2,(3,1)).float()\n",
        "d = torch.randint(1,2,(2,)).float()\n",
        "\n",
        "# Tensor 1D ( vector)\n",
        "# tensor 2D ( metrix)\n",
        "# tensor 3D ( stack of metrix) (batches oif metrix)\n",
        "    # (batch, Time, channel)\n",
        "    # (batch, seq length, embd vector dim)\n",
        "# tensor 4D \n",
        "    # (batch, hight, widh, channle)\n",
        "\n",
        "\n",
        "# c: A 2D tensor (matrix) with shape (1, 2), \n",
        "# meaning 1 row and 2 columns.\n",
        "# d: A 1D tensor (vector) with shape (2,), \n",
        "# meaning it has only 2 elements in a \n",
        "# single dimension, without explicit rows or columns.\n",
        "\n",
        "# c has two elements arranged in a row: \n",
        "# [[1., 1.]] (2D).\n",
        "# d has two elements in a single dimension: \n",
        "# [1., 1.] (1D).\n",
        "\n",
        "print(f\"{b=}\")\n",
        "print(f\"{b.shape=}\")\n",
        "print(f\"{c=}\")\n",
        "print(f\"{c.shape=}\")\n",
        "print(f\"{e=}\")\n",
        "print(f\"{e.shape=}\")\n",
        "print(f\"{d=}\")\n",
        "print(f\"{d.shape=}\")\n",
        "\n",
        "print(f\"-----------------------\")\n",
        "print(f\"{b+c=}\")\n",
        "print(f\"{b+e=}\")\n",
        "print(f\"{b+d=}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tril=tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "wei=tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "weim=tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "weis=tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "-----------------------------------------\n",
            "x[0]=tensor([[4., 2.],\n",
            "        [2., 2.],\n",
            "        [3., 2.],\n",
            "        [4., 2.],\n",
            "        [3., 3.],\n",
            "        [2., 4.],\n",
            "        [2., 4.],\n",
            "        [2., 2.]])\n",
            "xbow3[0]=tensor([[4.0000, 2.0000],\n",
            "        [3.0000, 2.0000],\n",
            "        [3.0000, 2.0000],\n",
            "        [3.2500, 2.0000],\n",
            "        [3.2000, 2.2000],\n",
            "        [3.0000, 2.5000],\n",
            "        [2.8571, 2.7143],\n",
            "        [2.7500, 2.6250]])\n"
          ]
        }
      ],
      "source": [
        "# version 2: use Softmax\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "\n",
        "weim = wei.masked_fill(tril == 0, float('-inf'))\n",
        "weis = F.softmax(weim, dim= -1)\n",
        "# sof = e^x/sum (e^x1 + ....)\n",
        "xbow3 = weis @ x\n",
        "\n",
        "\n",
        "print(f\"{tril=}\")\n",
        "print(f\"{wei=}\")\n",
        "print(f\"{weim=}\")\n",
        "print(f\"{weis=}\")\n",
        "\n",
        "print(f\"-----------------------------------------\")\n",
        "print(f\"{x[0]=}\")\n",
        "print(f\"{xbow3[0]=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# comparision of all the three method\n",
        "# of doing same thing\n",
        "\n",
        "# version 1: using loop\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "#---------------------------------------------------\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "\n",
        "print(torch.allclose(xbow, xbow2))\n",
        "\n",
        "#--------------------------------------\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "\n",
        "print(torch.allclose(xbow, xbow3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# out of the above three version \n",
        "# we will use the last one\n",
        "\n",
        "# elf-attention!\n",
        "#-------------------\n",
        "#--------------------\n",
        "\n",
        "# in self attention the weight matrix wei of zeors will \n",
        "# get replaced by the metrix multiplication of query @ key.transpose()\n",
        "# wei =  query @ key.transpose()\n",
        "\n",
        "# now the value of wei will depend on query and key\n",
        "# and these query and keys value depens on the \n",
        "# embedding vectors corros to each word in embedd matrix\n",
        "# so as the optimisation goes on emedding metrix updates its vectors\n",
        "# corrospond to each token.\n",
        "# so the query key updaets accordingly \n",
        "# which will again contribute in the \n",
        "# calculation of weighted avg of past time spteps\n",
        "# it will fluctuate the weight corrosponds to the perticular char in the past time step\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "# role of softmax\n",
        "# convert it in prob\n",
        "# exponent gives the near 0 values for the extream -ive values \n",
        "# and at the same time it will convert\n",
        "# all the -values to + value\n",
        "# so the numeric values will be in good shape\n",
        "\n",
        "# mask used\n",
        "# so that future cant comm with past\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# role of softmax\n",
        "# convert it in prob\n",
        "# exponent gives the near 0 values for the extream -ive values \n",
        "# and at the same time it will convert\n",
        "# all the -values to + value\n",
        "# so the numeric values will be in good shape\n",
        "\n",
        "# mask used\n",
        "# so that future cant comm with past\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can think it as\n",
        "# lets [token1,token2,token3,...]\n",
        "# so for any token \n",
        "# we are calculating the weighted avg of past tokens\n",
        "# considening the contribution of any past token to that token \n",
        "# which will decieded by the weight metrix wei\n",
        "# in the optimisation process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k.shape=torch.Size([4, 8, 16])\n",
            "q.shape=torch.Size([4, 8, 16])\n",
            "k.var()=tensor(1.0204)\n",
            "q.var()=tensor(1.0632)\n",
            "wei.var()=tensor(14.6308)\n",
            "---------------------------\n",
            "k.var()=tensor(0.9891)\n",
            "q.var()=tensor(1.0652)\n",
            "wei.var()=tensor(1.0078)\n"
          ]
        }
      ],
      "source": [
        "# self attention :\n",
        "# when the query key and values are from the same source\n",
        "# cross attention :\n",
        "# when query commimg from different sounrce \n",
        "# and key values are from different source\n",
        "\n",
        "# encode :\n",
        "# here we dont use mask\n",
        "# all the tokens interact with each other\n",
        "# use self attention\n",
        "\n",
        "\n",
        "# decode :\n",
        "# here we use cross attention \n",
        "# bxz key value comes from encoder side\n",
        "# query comes from decoder \n",
        "# also use masked self attention\n",
        "\n",
        "# GPT:\n",
        "# has masked self attention only\n",
        "# not cross attention\n",
        "\n",
        "# 2017 attention all need paaper\n",
        "# attention ( Q,K,V) = (softmax(QK.T)/root(dk))*v\n",
        "# dk = head size (16)\n",
        "\n",
        "# we are multpliying root(dk)\n",
        "# to preserve the variance of wei\n",
        "# if not mul by it var will increase to aprox head size\n",
        "\n",
        "# why its import\n",
        "# bcz at the intialization wei has to be farely diffused\n",
        "# if the wei values are fairly diffeyused around near zero than\n",
        "# out of soft max will be ok\n",
        "# if the wei values are extream \n",
        "# than oyut of softmax will be tend to onhot encoding\n",
        "# out sofmax will become peeky\n",
        "\n",
        "head_size = 16\n",
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2,-1)\n",
        "print(f\"{k.shape=}\")\n",
        "print(f\"{q.shape=}\")\n",
        "print(f\"{k.var()=}\")\n",
        "print(f\"{q.var()=}\")\n",
        "print(f\"{wei.var()=}\")\n",
        "\n",
        "\n",
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2,-1) * head_size**-0.5\n",
        "print(f\"---------------------------\")\n",
        "print(f\"{k.var()=}\")\n",
        "print(f\"{q.var()=}\")\n",
        "print(f\"{wei.var()=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "tensor([0.1438, 0.0585, 0.2620, 0.0585, 0.4773])\n",
            "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ],
      "source": [
        "print(torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5]), dim = -1))\n",
        "print(torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5])*3, dim = -1))\n",
        "print(torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5])*8, dim = -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 1, 0, 1])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ix = torch.randint(6 - 3, (4,))\n",
        "ix.shape\n",
        "ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15, 15, 12, 10])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [i for i in range(20)]\n",
        "\n",
        "ix = torch.randint(20-3, (4,))\n",
        "ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4, 5, 6], [2, 3, 4], [13, 14, 15], [6, 7, 8]] [[5, 6, 7], [3, 4, 5], [14, 15, 16], [7, 8, 9]]\n"
          ]
        }
      ],
      "source": [
        "x = [data[i:i+3] for i in ix]\n",
        "y = [data[i+1:i+3+1] for i in ix]\n",
        "print(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[15, 16, 17],\n",
              "        [15, 16, 17],\n",
              "        [12, 13, 14],\n",
              "        [10, 11, 12]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.stack([torch.tensor(data[i:i+3]) for i in ix])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[5, 6, 7], [3, 4, 5], [14, 15, 16], [7, 8, 9]]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "random_tensor = torch.randn(4, 8, 10)\n",
        "print(random_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l = torch.nn.Linear(10, 200)\n",
        "l2 = torch.nn.Linear(200,10 )\n",
        "l2(l(random_tensor)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l = torch.nn.Linear(10*8, 200)\n",
        "l2 = torch.nn.Linear(200, 10*8)\n",
        "l(random_tensor.reshape(4,10*8)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 80])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l2(l(random_tensor.reshape(4,10*8))).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 5])\n",
            "torch.Size([4, 8, 5])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "a1 = torch.randn(4, 8, 5)\n",
        "print(a1.shape)\n",
        "a2 = torch.randn(4, 8, 5)\n",
        "print(a2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.concat([a1, a2], dim = -1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 9])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "a1 = torch.randn(4, 9)\n",
        "print(a1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1[:, -3:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3912,  0.7407, -0.0651,  0.9849, -0.6156,  0.0040,  0.4691, -0.5427,\n",
              "         -0.7073],\n",
              "        [ 0.7824, -0.2396,  1.4771,  0.2353,  0.2687, -0.0293,  0.0441, -0.1262,\n",
              "         -1.0035],\n",
              "        [ 0.5595, -0.4299, -1.0468, -0.2405, -0.1348,  2.1035, -0.8706,  0.4621,\n",
              "          0.2323],\n",
              "        [ 0.9974, -0.4518, -0.2659, -0.5539, -2.6855, -1.5831, -1.0538, -0.1206,\n",
              "          0.1416]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.4691, -0.5427, -0.7073],\n",
              "        [ 0.0441, -0.1262, -1.0035],\n",
              "        [-0.8706,  0.4621,  0.2323],\n",
              "        [-1.0538, -0.1206,  0.1416]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1[:, -3:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 2])\n"
          ]
        }
      ],
      "source": [
        "a1 = torch.randn(1, 8, 2)\n",
        "print(a1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1[:, -1, :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.0259,  0.2584],\n",
              "         [-0.0914,  0.1731],\n",
              "         [ 0.3069, -1.6863],\n",
              "         [-1.1862,  0.6586],\n",
              "         [ 1.2723, -0.1566],\n",
              "         [-0.3084, -0.1227],\n",
              "         [-0.0108,  1.3207],\n",
              "         [-0.6291, -0.1495]]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.6291, -0.1495]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1[:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.Size([4, 8])\n",
        "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
        "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
        "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
        "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
        "targets:\n",
        "torch.Size([4, 8])\n",
        "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
        "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
        "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
        "        [17, 27, 10,  0, 21,  1, 54, 39]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]),\n",
              " tensor([[ 1.3938],\n",
              "         [ 0.5535],\n",
              "         [ 0.3968],\n",
              "         [-0.6233]]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1 = torch.randn(4,1)\n",
        "a1.shape, a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.concat([a1,a1], dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat([a1,a1],dim = 1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.3938,  1.3938],\n",
              "        [ 0.5535,  0.5535],\n",
              "        [ 0.3968,  0.3968],\n",
              "        [-0.6233, -0.6233]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.concat((a1,a1),dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "context = torch.zeros((1,1), dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 10]),\n",
              " tensor([[-1.1420,  1.1814,  0.3576, -1.8297,  1.4613,  0.8432,  0.1185, -0.2978,\n",
              "          -2.2559,  1.3797],\n",
              "         [-0.5352, -1.2428, -1.2278, -0.4866, -0.8216, -0.7622, -0.2490,  0.1305,\n",
              "          -0.1554, -0.2390],\n",
              "         [-0.5165,  0.5301,  0.7900, -0.2255,  0.2253,  2.3023,  0.5821,  0.5180,\n",
              "          -0.1326,  1.0209],\n",
              "         [-1.3290,  0.0755,  1.2942,  1.6286, -0.4758,  0.7090, -1.0108, -0.2441,\n",
              "          -1.1692, -0.1003]]))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1 = torch.randn(4,10)\n",
        "a1.shape, a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-1.142049789428711,\n",
              " 1.181437373161316,\n",
              " 0.357624888420105,\n",
              " -1.8296600580215454,\n",
              " 1.461300015449524,\n",
              " 0.8432005643844604,\n",
              " 0.11845407634973526,\n",
              " -0.29782533645629883,\n",
              " -2.255922317504883,\n",
              " 1.3797030448913574]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([19])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(19).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gpt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
