{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n",
      "total length: 216121\n"
     ]
    }
   ],
   "source": [
    "# create combined dataset from the kaggle txt files\n",
    "\n",
    "import os\n",
    "files = os.listdir(\"hindi_data\")\n",
    "lines = []\n",
    "for file in files:\n",
    "    it = 0\n",
    "    path = os.path.join(\"hindi_data\", file)\n",
    "    with open(path , 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "        text = text[1:-2]\n",
    "    \n",
    "    # Remove zero-width non-joiner '\\u200c' from each line\n",
    "    text = [line.replace('\\u200c', '') for line in text]\n",
    "\n",
    "    lines.extend(text)\n",
    "    it = it+1\n",
    "\n",
    "    \n",
    "# Open a text file in write mode\n",
    "with open('hindi.txt', 'a', encoding='utf-8') as f:\n",
    "    # Write each line to the file\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(\"File saved successfully!\")\n",
    "print(f\"total length: {len(lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size=84\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "data_path = \"hindi.txt\"\n",
    "torch.manual_seed(1337)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#---------------------------------------------------\n",
    "# Data Preperation:\n",
    "#-----------------------------------\n",
    "#----------------------------------------------\n",
    "\n",
    "# load dataset:\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# text to numeric ids conversion:\n",
    "#-------------------------------------\n",
    "# create vocab:\n",
    "# vocab: all the unique chars in the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"{vocab_size=}\")\n",
    "# create mapping: chars to numeric ids\n",
    "stoi = { ch:id for id, ch in enumerate(chars) }\n",
    "itos = { id:ch for id, ch in enumerate(chars) }\n",
    "\n",
    "# create encoder/decoder:\n",
    "encode = lambda s : [stoi[c] for c in s] # takes a string output list of integers\n",
    "decode = lambda l : \"\".join([itos[i] for i in l]) # takes a list of intgs and output string of chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '?',\n",
       " '|',\n",
       " 'ँ',\n",
       " 'ं',\n",
       " 'अ',\n",
       " 'आ',\n",
       " 'इ',\n",
       " 'ई',\n",
       " 'उ',\n",
       " 'ऊ',\n",
       " 'ए',\n",
       " 'ऐ',\n",
       " 'ओ',\n",
       " 'औ',\n",
       " 'क',\n",
       " 'ख',\n",
       " 'ग',\n",
       " 'घ',\n",
       " 'च',\n",
       " 'छ',\n",
       " 'ज',\n",
       " 'झ',\n",
       " 'ट',\n",
       " 'ठ',\n",
       " 'ड',\n",
       " 'ढ',\n",
       " 'ण',\n",
       " 'त',\n",
       " 'थ',\n",
       " 'द',\n",
       " 'ध',\n",
       " 'न',\n",
       " 'प',\n",
       " 'फ',\n",
       " 'ब',\n",
       " 'भ',\n",
       " 'म',\n",
       " 'य',\n",
       " 'र',\n",
       " 'ल',\n",
       " 'व',\n",
       " 'श',\n",
       " 'स',\n",
       " 'ह',\n",
       " '़',\n",
       " 'ा',\n",
       " 'ि',\n",
       " 'ी',\n",
       " 'ु',\n",
       " 'ू',\n",
       " 'ृ',\n",
       " 'े',\n",
       " 'ै',\n",
       " 'ॉ',\n",
       " 'ो',\n",
       " 'ौ',\n",
       " '्',\n",
       " 'क़',\n",
       " 'ख़',\n",
       " 'ग़',\n",
       " 'ज़',\n",
       " 'ड़',\n",
       " 'ढ़',\n",
       " 'फ़',\n",
       " '।']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
