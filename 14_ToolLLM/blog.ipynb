{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToolLLM - Empowering Open-Source Models for Advanced Tool Use\n",
    "\n",
    "In recent years, large language models (LLMs) like LLaMA have achieved remarkable success in natural language tasks. However, their capabilities in leveraging external tools, such as APIs, remain limited. Unlike state-of-the-art (SOTA) closed-source LLMs like ChatGPT, which excel in tool usage, open-source LLMs have struggled to integrate such capabilities effectively. This is where **ToolLLM** emerges as a game-changer, enhancing tool-use capabilities in open-source models, particularly LLaMA.\n",
    "\n",
    "In this blog post, we’ll explore the technical intricacies of ToolLLM, its novel components like ToolBench, ToolEval, and API retriever, and how it compares to other frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction to ToolLLM**\n",
    "\n",
    "ToolLLM is a comprehensive framework designed to imbue open-source LLMs with robust tool-use capabilities. It focuses on the following core areas:\n",
    "\n",
    "1. **Data Construction**: Leveraging diverse, real-world APIs to create a comprehensive training dataset.\n",
    "2. **Model Training**: Fine-tuning LLaMA to interact effectively with external tools.\n",
    "3. **Evaluation**: Developing metrics and benchmarks to measure tool-use efficiency and robustness.\n",
    "\n",
    "Unlike traditional instruction tuning, which emphasizes language tasks, ToolLLM prioritizes the integration and interaction with external APIs. Its foundation lies in **ToolBench**, an instruction-tuning dataset tailored for tool use.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Components of ToolLLM**\n",
    "\n",
    "### 1. **ToolBench**: A Dataset for Tool Use\n",
    "\n",
    "ToolBench serves as the backbone of ToolLLM, enabling it to learn and generalize tool-usage capabilities. The dataset creation involves three critical steps:\n",
    "\n",
    "#### a) **API Collection**  \n",
    "Using **RapidAPI Hub**, ToolBench incorporates 16,464 real-world RESTful APIs across 49 categories, including social media, e-commerce, and weather. These APIs provide diverse scenarios to ensure the model can generalize to unseen APIs.\n",
    "\n",
    "Key details collected for each API include:\n",
    "- Name and description\n",
    "- HTTP method and parameters\n",
    "- Example API calls and responses\n",
    "\n",
    "#### b) **Instruction Generation**  \n",
    "ToolBench uses **ChatGPT** (gpt-3.5-turbo-16k with function call capabilities) to generate diverse instructions for single-tool and multi-tool scenarios. This process ensures:\n",
    "- **Diversity**: Training LLMs for a broad range of API usage scenarios.\n",
    "- **Multi-tool Interaction**: Reflecting real-world tasks requiring multiple APIs.\n",
    "\n",
    "Generated instructions include:\n",
    "- API functionalities\n",
    "- Seed examples for context and clarity\n",
    "\n",
    "#### c) **Solution Path Annotation**  \n",
    "To annotate solution paths, ToolLLM employs a **depth-first search-based decision tree (DFSDT)**, enabling efficient planning and reasoning. APIs are treated as functions, and ChatGPT generates valid sequences of API calls to complete instructions.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Fine-Tuning with ToolLLaMA**\n",
    "\n",
    "ToolLLM fine-tunes LLaMA into **ToolLLaMA**, incorporating a neural API retriever. The API retriever identifies relevant APIs based on the given instruction and facilitates multi-round decision-making. ToolLLaMA demonstrates:\n",
    "\n",
    "- **Zero-shot generalization**: Exceptional performance on unseen APIs and datasets.\n",
    "- **Par performance with ChatGPT**: Effectiveness on **APIBench**, an out-of-distribution dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **ToolEval: Automated Evaluation**\n",
    "\n",
    "Evaluating tool-use capabilities requires rigorous benchmarks. ToolLLM introduces **ToolEval**, an automatic evaluator with two key metrics:\n",
    "\n",
    "1. **Pass Rate**: Measures the success of completing instructions within a limited budget.\n",
    "2. **Win Rate**: Compares the quality and efficiency of solution paths.\n",
    "\n",
    "ToolEval utilizes ToolBench data and ChatGPT to assess reasoning processes and validate results.\n",
    "\n",
    "---\n",
    "\n",
    "## **Technical Advancements in ToolLLM**\n",
    "\n",
    "ToolLLM incorporates several novel techniques to enhance LLM capabilities:\n",
    "\n",
    "1. **Depth-First Search Decision Tree (DFSDT)**  \n",
    "   - Expands search space for reasoning.\n",
    "   - Prioritizes valid paths over exhaustive exploration, ensuring efficiency.\n",
    "\n",
    "2. **Neural API Retriever**  \n",
    "   - Trained to recommend relevant APIs based on instruction context.\n",
    "   - Ensures accurate and efficient tool selection.\n",
    "\n",
    "3. **Instruction Sampling Strategies**  \n",
    "   - Diverse combinations of APIs are sampled to cover a wide range of scenarios, improving generalizability.\n",
    "\n",
    "---\n",
    "\n",
    "## **Experimental Results**\n",
    "\n",
    "### **Performance on APIBench**\n",
    "ToolLLaMA exhibits strong performance on APIBench, matching Gorilla, a pipeline specifically designed for API interaction. It also showcases:\n",
    "\n",
    "- **Complex Instruction Execution**: Effectively handles intricate multi-tool tasks.\n",
    "- **Zero-Shot Generalization**: Excels in unseen scenarios, highlighting robustness.\n",
    "\n",
    "### **Comparison with ChatGPT**\n",
    "ToolLLaMA achieves comparable results to ChatGPT in tool-use tasks, making it a viable open-source alternative for API interaction.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications of ToolLLM**\n",
    "\n",
    "1. **Real-World Integrations**  \n",
    "   - Automating workflows with multi-tool interactions.\n",
    "   - Enhancing customer support through dynamic API use.\n",
    "\n",
    "2. **Open-Source Development**  \n",
    "   - Democratizing advanced tool-use capabilities.\n",
    "   - Facilitating innovative applications in research and industry.\n",
    "\n",
    "3. **Educational and Research Tools**  \n",
    "   - Providing a robust framework for studying tool-use in LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "ToolLLM is a pioneering framework that bridges the gap between open-source and closed-source LLMs in tool-use capabilities. By leveraging ToolBench, ToolEval, and advanced techniques like DFSDT, ToolLLM empowers open-source models like LLaMA to perform complex tasks requiring external APIs.\n",
    "\n",
    "With its remarkable performance and open-source availability, ToolLLM paves the way for future innovations in LLM tool-use capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "**Resources**  \n",
    "For codes, trained models, and a demo, visit the [ToolBench GitHub repository](https://github.com/OpenBMB/ToolBench)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
